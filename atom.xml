<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>态度决定高度,细节决定成败</title>
  
  <subtitle>疯狂的码农</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.fengqinglei.top/"/>
  <updated>2019-10-21T02:01:47.860Z</updated>
  <id>https://www.fengqinglei.top/</id>
  
  <author>
    <name>FQL</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Text Retrieval and Search Engines 2</title>
    <link href="https://www.fengqinglei.top/2019/10/17/text-retrieval-and-search-engines-3/"/>
    <id>https://www.fengqinglei.top/2019/10/17/text-retrieval-and-search-engines-3/</id>
    <published>2019-10-16T16:20:21.000Z</published>
    <updated>2019-10-21T02:01:47.860Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Text-Retrieval-and-Search-Engines学习笔记-三"><a href="#Text-Retrieval-and-Search-Engines学习笔记-三" class="headerlink" title="Text Retrieval and Search Engines学习笔记(三)"></a><font color="#0077bb">Text Retrieval and Search Engines学习笔记(三)</font></h1><p>这篇文章是继上一篇<a href="https://www.fengqinglei.top/2019/10/09/text-retrieval-and-search-engines-2/">Text Retrieval and Search Engines学习笔记(二)</a> 的后续部分，这一篇我们重点介如何绍改进<strong>Vector Space Model</strong></p><h2 id="Vector-Space-Model"><a href="#Vector-Space-Model" class="headerlink" title="Vector Space Model"></a><font color="#0077bb">Vector Space Model</font></h2><p>在上一篇我们介绍了由<strong>BOW</strong>模型和<strong>Dot Product</strong>相似度计算方法组成的<strong>Simplest Vector Model</strong> ,在某种成都上说，这个方法确实解决了一些我们对文档排序的一些需求，但是从上面的例子中我们也可以简单的发现两个问题:<br><a id="more"></a><br><img src="https://s2.ax1x.com/2019/10/19/Kn4ADs.png" alt="Kn4ADs.png"></p><h3 id="文档中出现关键字presidential越多，分数应该越高"><a href="#文档中出现关键字presidential越多，分数应该越高" class="headerlink" title="文档中出现关键字presidential越多，分数应该越高"></a><font color="#0077bb">文档中出现关键字<strong>presidential</strong>越多，分数应该越高</font></h3><p>针对这个问题，我们可以使用关键字出现的次数替换<strong>BOW</strong>模型中的{0,1}表示方法，即如果文章中出现了关键词，那么将原来的1替换成在该文章中出现某关键词的次数，而如果没有出现，那么还是0保持不变,也就是说我们的similarity计算公式变为: Sim(q,d)=x’<sub>1</sub>y’<sub>1</sub>+…+x’<sub>i</sub>y’<sub>i</sub>=$\sum_{i=1}^N$x’<sub>i</sub>y’<sub>i</sub>(这里的x’<sub>i</sub>=Count(W<sub>i</sub>,q)表示关键词W<sub>i</sub>在query中出现的次数,y’<sub>i</sub>=Count(W<sub>i</sub>,d)表示关键词W<sub>i</sub>在文档出现的次数，一般来说x<sub>i</sub>的值都是1)<br><img src="https://s2.ax1x.com/2019/10/19/Kn42Pf.png" alt="Kn42Pf.png"><br>我们将改进过的similarity计算方式重新计算<strong>Simplest Vector Space Model</strong>中的例子:<br><img src="https://s2.ax1x.com/2019/10/19/Kn5Kot.png" alt="Kn5Kot.png"><br>我们可以看到Sim(q,d<sub>4</sub>的分数从原来的<strong>3</strong>变成了<strong>4</strong>)，确实这样的改动能够达到我们的诉求。</p><h3 id="关键字presidential要比关键词about的权重更高"><a href="#关键字presidential要比关键词about的权重更高" class="headerlink" title="关键字presidential要比关键词about的权重更高"></a><font color="#0077bb">关键字<strong>presidential</strong>要比关键词<strong>about</strong>的权重更高</font></h3><p>当我们仔细的去分析/理解query<strong>news about presidential campaign</strong>,的时候我们会自然而然的认为关键词<strong>presidential</strong>应该比<strong>about</strong>总要-&gt; 为什么？，我们为什么会得出这样的结论，这几乎是所有正常人都会得出的结论—&gt; 因为我们看到的太多了，这就好比我们每天都看到/遇到各种个样的人,这时候你在路上遇到个人你会觉得这是一件非常正常的事情,但是如果哪天你在路上看见一头大象你一定非常的在意这头大象，因为它太少见了.同样的道理，因为关键词<strong>about</strong>几乎出现在所有的文章中，那么关键字<strong>about</strong>也就没有关键字<strong>presidential</strong>那么”值钱”了，为了解决这种常见词的问题，我们这里可以使用IDF(逆文档频率来解决这个问题),<strong>IDF(W)=log[(M+1)/k]</strong>,k表示有多少文档中出现了关键词<strong>W</strong> (和出现次数没有关系)<br><img src="https://s2.ax1x.com/2019/10/19/Kn7F7d.png" alt="Kn7F7d.png"><br>那么改进之后的Sim计算方法为:Sim(q,d)=x’<sub>1</sub>y’’<sub>1</sub>+…+x’<sub>i</sub>y’’<sub>i</sub>=$\sum_{i=1}^N$x’<sub>i</sub>y’’<sub>i</sub>(这里的x’<sub>i</sub>=Count(W<sub>i</sub>,q)表示关键词W<sub>i</sub>在query中出现的次数,y’’<sub>i</sub>=Count(W<sub>i</sub>,d)*IDF(W<sub>i</sub>)表示关键词W<sub>i</sub>在文档出现的次数乘以关键词W<sub>i</sub>的逆文档频率，我们没有将IDF应用到query中的关键词的权重计算中，个人理解是因为用户的query中的关键字一定是重要的词，不然为啥要当成检索式的组成要素，但是文本中的关键词因为表达的意义比较多会有主次之分),我们将改进之后的公式应用到同样的例子中(我们现对比下d2,d3,因为d2,d3的得分是一样的))<br><img src="https://s2.ax1x.com/2019/10/19/KnbaTJ.png" alt="KnbaTJ.png"><br>我们可以看到在引入idf之后d3文档的得分按照我们的想法得到的更多的提升，从而使用f(q,d2)=5.6 &lt; f(q,d3)=7.1 ,这样两个文档之间因为得分不一样从而产生了区分度，我们也可以将文档d3排在文档d2的前面。</p><p>至此，我们通过使用<strong>TF</strong>, <strong>IDF</strong>分别解决了上述两个问题，我们来计算下所有的文档和query的相关度,看看这种计算方法是不是在所有情况下都能反应文档和query的真实相关度，<br><img src="https://s2.ax1x.com/2019/10/19/Knq7CR.png" alt="Knq7CR.png"><br>我们在上一篇文章中说过，一种idea的排序应该是(d4+, d3+ ,d1- ,d2- d5- ),貌似d4,d3,d1,d3的顺序和分数已经达到了我们想要的效果，但是d5的得分却是13.9，这和我们的期望相差的有点大。。。。</p><h3 id="TF-Transformation-解决词频轰炸"><a href="#TF-Transformation-解决词频轰炸" class="headerlink" title="TF Transformation,解决词频轰炸"></a><font color="#0077bb">TF Transformation,解决词频轰炸</font></h3><p>首先我们得明白为什么d5的相似度为13.9,这里我们可以分析下我们的rank方法f(q,d)=$\sum_{i=1}^N$x<sub>i</sub>y<sub>i</sub>=$\sum_{w \in q \cap w}$c(w,q)c(w,d)log$\frac{M+1}{df(w)}$, 不难发现f(q,d5)=13.9的原始是c(campaign,d5)=4, 这里idf(campaign)对于所有包含关键词campaign的文档来说都是一样的，为了解决这种高tf所带来的问题，我们需要对t这一指标进行改写，这里我们介绍<strong>BM25</strong>模型对tf的改写规则: TF(w,d) = $\frac{(k+1)x}{x+k}$,不难发现该函数有个特性就是上界为<strong>k+1</strong>,这里我们解释下，为什么不使用log函数对tf进行平滑？我们可以现看下这几个函数的走势图:<br><img src="https://s2.ax1x.com/2019/10/20/KnxNgs.png" alt="KnxNgs.png"><br>从图中我们可以看出，log函数是没有上界的，当k非常大的时候经过log函数的变化，结果依然会很大，假设我在网上发了一篇关于某主题的文章，文章的内容就是重复某个关键字几万甚至几十万次，那么如果我检索改关键词，那么这篇文章按照我们目前定义的函数来计算相似度的话，一定是排第一的，但是显然这又是非常不合理的(文章没有实质性的内容),所以为了不出现上述这种词频轰炸的问题，我们必须设置一个词频对分数影响的上届，当词频超过一定数量之后，它的影响不会随着tf的增加而发生缓慢的变化，并且这种变化有一个理论上的尽头。</p><p>经过上述对两个问题的分析和提出的解决方案，我们可以得到:<br>f(q,d) = $\sum_{i=1}^{N}$x<sub>i</sub>y<sub>i</sub>=$\sum_{w \in q \cap w}C(w,q)\frac{(k+1)C(w,d)}{C(w,d)+k}log\frac{M+1}{df}(w)$,其中</p><div class="table-container"><table><thead><tr><th>符号名称</th><th>符号含义</th></tr></thead><tbody><tr><td>C(w,q)</td><td>表示关键词w<sub>i</sub>在query中出现的次数，一般都是1词</td></tr><tr><td>M</td><td>表示文档的总数</td></tr><tr><td>df(W)</td><td>表示关键词w<sub>i</sub>在文档d中出现的次数</td></tr></tbody></table></div><h3 id="文档长度也需要考虑在其中"><a href="#文档长度也需要考虑在其中" class="headerlink" title="文档长度也需要考虑在其中"></a><font color="#0077bb">文档长度也需要考虑在其中</font></h3><p>除了词频和低频词的问题，正常来说大家都会发现文档有长有短，一般来说都是文章越长，命中某个query关键字的概率也就越大(不绝对，但是有一定的可信度),所以类似tf的处理规则一样，我们得对文档长度进行处理。我们使用<strong>Pivoted Length Normalization</strong>规则对文档的长度进行处理具体的公式为</p><p>normalizer = 1 -b + b$\frac{|d|}{avdl}$ (其中avdl是所有文档的平均长度,并且b$ \in [0,1]$)<br>如果b=0,那么normalizer=1 ,也就是说这个时候文档长度不参与最终的打分，当b&gt;0时，如果某个文档的长度超过平均文档长度，那么随着b增加，normalizer的取值也就越大(这里注意最终的分数是越小的，因为我们要对这种长文档进行降分处理),当文档长度小于平均长度的时候，normalizer的取值也就越小(但是一定是大于0的),最终的分数应该是越大的，因为我们要对短文档的分数进行一定的补偿，也就是说b的值越大，对文档长度的打分的降低或者补偿的力度越大。从下面的图中，大家可以有个直观的理解。<br><img src="https://s2.ax1x.com/2019/10/21/KQNz1x.png" alt="KQNz1x.png"></p><h2 id="最终的打分公式"><a href="#最终的打分公式" class="headerlink" title="最终的打分公式"></a><font color="#0077bb">最终的打分公式</font></h2><p>到这里，加上我们对文档长度的处理，我们可以得到最终的BM25打分公式为:<br>f(q,d) = $\sum_{w \in q \cap d}$ [C(w,q) $\frac{(k+1)C(w,d)}{C(w,d)+k(1-b+b \frac {d}{avdl})}$log$\frac{M+1}{df(w)}$)]<br>其中:<br>C(w,q)= 关键词w在query中出现的次数，一般为1<br>C(w,q)= 关键词w在文档中出现的次数<br>k为正实数 k&gt;0<br>b的取值范围为 b $\in [0,1] $<br>M 表示文档总数<br>df(w) 所有关键词w出现的文档的总数。<br>当然BM25只是vector space model的一种实现，而实验证明还有另外一种实现也和BM25一样高效, 即 <strong>Pivoted Length Normalization VSM</strong>,这里我们直接给出它的打分公式:<br><img src="https://s2.ax1x.com/2019/10/21/KQ09Gd.png" alt="KQ09Gd.png"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><font color="#0077bb">总结</font></h2><p>到这里我们简单介绍了<strong>Simplest Vector Space Model</strong>所面临的问题，以及我们相应的改进方案，从0～1的介绍了BM25算法公式的由来和实现，在一篇中我们将介绍如何高效的计算BM25打分公式，毕竟真实场景中我们遇到的文档数量可能是千万甚至几十亿的级别，我们要以高效的计算方式实现BM25,否则一个检索式输入到系统中，我们到等几分钟或者几个小时才能得到答案，这肯定是不现实的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Text-Retrieval-and-Search-Engines学习笔记-三&quot;&gt;&lt;a href=&quot;#Text-Retrieval-and-Search-Engines学习笔记-三&quot; class=&quot;headerlink&quot; title=&quot;Text Retrieval and Search Engines学习笔记(三)&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#0077bb&quot;&gt;Text Retrieval and Search Engines学习笔记(三)&lt;/font&gt;&lt;/h1&gt;&lt;p&gt;这篇文章是继上一篇&lt;a href=&quot;https://www.fengqinglei.top/2019/10/09/text-retrieval-and-search-engines-2/&quot;&gt;Text Retrieval and Search Engines学习笔记(二)&lt;/a&gt; 的后续部分，这一篇我们重点介如何绍改进&lt;strong&gt;Vector Space Model&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;Vector-Space-Model&quot;&gt;&lt;a href=&quot;#Vector-Space-Model&quot; class=&quot;headerlink&quot; title=&quot;Vector Space Model&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#0077bb&quot;&gt;Vector Space Model&lt;/font&gt;&lt;/h2&gt;&lt;p&gt;在上一篇我们介绍了由&lt;strong&gt;BOW&lt;/strong&gt;模型和&lt;strong&gt;Dot Product&lt;/strong&gt;相似度计算方法组成的&lt;strong&gt;Simplest Vector Model&lt;/strong&gt; ,在某种成都上说，这个方法确实解决了一些我们对文档排序的一些需求，但是从上面的例子中我们也可以简单的发现两个问题:&lt;br&gt;
    
    </summary>
    
    
      <category term="NLP" scheme="https://www.fengqinglei.top/tags/NLP/"/>
    
      <category term="Text Retrieval" scheme="https://www.fengqinglei.top/tags/Text-Retrieval/"/>
    
      <category term="Vector Space Model" scheme="https://www.fengqinglei.top/tags/Vector-Space-Model/"/>
    
      <category term="Search Engine" scheme="https://www.fengqinglei.top/tags/Search-Engine/"/>
    
      <category term="Probabilistic Model" scheme="https://www.fengqinglei.top/tags/Probabilistic-Model/"/>
    
  </entry>
  
  <entry>
    <title>Text Retrieval and Search Engines 2</title>
    <link href="https://www.fengqinglei.top/2019/10/09/text-retrieval-and-search-engines-2/"/>
    <id>https://www.fengqinglei.top/2019/10/09/text-retrieval-and-search-engines-2/</id>
    <published>2019-10-09T12:23:02.000Z</published>
    <updated>2019-10-16T16:22:07.003Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Text-Retrieval-and-Search-Engines学习笔记-二"><a href="#Text-Retrieval-and-Search-Engines学习笔记-二" class="headerlink" title="Text Retrieval and Search Engines学习笔记(二)"></a><font color="#0077bb">Text Retrieval and Search Engines学习笔记(二)</font></h1><p>这篇文章是继上一篇<a href="https://www.fengqinglei.top/2019/10/09/text-retrieval-and-search-engines-1/">Text Retrieval and Search Engines学习笔记(一)</a> 的后续部分，这一篇我们重点介绍如何定义和计算<strong>f(q,d)</strong></p><h2 id="Text-Retrieval-Methods"><a href="#Text-Retrieval-Methods" class="headerlink" title="Text Retrieval Methods"></a><font color="#0077bb">Text Retrieval Methods</font></h2><p>首先，我们得知道如何设计一个排序方法，这里我们可以列举一个好的排序方法都有那些特征或者属性</p><blockquote><ul><li>关于Query :q=q<sub>1</sub>,…,q<sub>m</sub>, q<sub>i</sub> $\in$ V</li><li>关于Document: d<sub>i</sub>=d<sub>i1</sub>,…,d<sub>ij</sub>, d<sub>ij</sub> $\in$ V</li><li>排序方法： f(q,d)$\in$R (这里表示排序方法的值在实数域，说人话就是可以取任意实数)</li><li>一个好的排序方法必须将相关的文档排在不相关的文档之前,那么问题来了，我们如何衡量query和document的相关的似然度呢？ </li><li>我们必须给排序模型/方法下一个明确的定义，并且这个定义还是可以明确计算的(说白了就是能够以数学公式的方式定义出来，我们可以通过数学公式计算出相关度)<a id="more"></a>好消息是，Text Retrieval 这个问题很久之前就已经出现了，前辈们已经给了我们可行的方法,下面我们列举一些召回模型。</li><li>Similarity-based models (基于相似度的模型)): f(q,d)=similarity(q,d) ,最常见的就是我们经常听说的<strong>Vector Space Model</strong> (空间向量模型)</li><li>Probabilistic models(概率模型): f(d,q)=p(R=1|d,q), 这里的R={0,1} （0表示不相关，1表示相关）,这里我们假设查询和文档都是来自随机变量的观察结果，常见的有<br>1.经典的概率模型(Classic probabilistic model)<br>2.<strong>语言模型(Language model)</strong><br>3.随机性偏差模型(Divergence-from-randomness model)</li><li>Probabilistic interence model (概率推理模型): f(q,d)=p(d-&gt;q) ,这类模型的想法是将不确定性与推理规则关联起来，然后我们可以量化某个query我们应该显示的文档的概率。</li><li>Axiomatic model(基于规则的)))): f(q,d) 必须匹配一些列的条件</li></ul></blockquote><p>虽然这些模型的出发点不尽相同，但是这些模型排序方法都类似，并且排序方法中都使用了类似的参数（例如：tf，|d|,df）等<br><img src="https://s2.ax1x.com/2019/10/09/uIbWNR.png" alt="commom ideas.png"><br>那么问题来了，我们有这么多模型可以选择，到底那个/些模型的效果是最好的？<br>实际上，当经过一些优化，下面的4中模型的效果是等价的</p><ul><li>Pivoted length normalization </li><li><strong>BM25</strong>(Solr的从5.x版本开始将BM25作为默认的排序模型)</li><li>Query likelihood</li><li>PL2<br><strong>BM25</strong>是空间向量模型的一种实现，下面我们就开始介绍<strong>Vector Space Model</strong></li></ul><h2 id="Vector-Space-Model"><a href="#Vector-Space-Model" class="headerlink" title="Vector Space Model"></a><font color="#0077bb">Vector Space Model</font></h2><p>空间向量模型的概念还是非常简单的: 把对文本内容的处理简化为向量空间中的向量运算，并且它以空间上的相似度表达语义的相似度，直观易懂。当文档被表示为文档空间的向量，就可以通过计算向量之间的相似性来度量文档间的相似性。文本处理中最常用的相似性度量方式是余弦距离。<br><img src="https://s2.ax1x.com/2019/10/09/uIv19s.png" alt="vector_space_model.png">,简单来说Vector Space Model是一个框架，每个term(最基本的概念，例如可以是一个单词或者词组)是一个纬度，query和文档都是有term组成，所以query和文档都可以映射成n维的向量，f(q,d)就是计算query和文档相似度的方法。虽然说这个一个从理论上可行的方法，但是vector Space Model在很多细节上并没有定义清楚，例如</p><blockquote><ul><li>如何定义/选择基础概念，因为基础向量是需要正交的</li><li>如何将文档和query映射到空间中(其实就是如何定义term的权重),因为term在query中的权重表示在这个term在这个query中的重要性，term在文档中的权重刻画了文档的特征</li><li>如何定义相似度的计算方式</li></ul></blockquote><p><img src="https://s2.ax1x.com/2019/10/11/uHTHUJ.png" alt="what_vsm_not_say.png"><br>也就是说Vector Space Model这个框架更多是在理论上解决了如果计算文档和query相似度(R<sup>,</sup>(q,d)),我们需要给出一种实现才能够真正解决我们的实际问题。</p><h3 id="Simplest-Vector-Space-Model"><a href="#Simplest-Vector-Space-Model" class="headerlink" title="Simplest Vector Space Model"></a><font color="#0077bb">Simplest Vector Space Model</font></h3><blockquote><ul><li>用<strong>Bag of words</strong>的方式来放置query和文档的向量<br>我们可以用{0,1}来构造query/文档向量，简单说就是如果某个term出现在文档中，那么我们用1标识，如果没有出现过，我们就使用0标识。(可以想象，query中向量中会有非常多的0，因为一般而言query比较短，但是文档比较长),这里我们可以令q=(x<sub>1</sub>,x<sub>2</sub>,…,x<sub>N</sub>) ,d=(y<sub>1</sub>,y<sub>2</sub>,…,y<sub>N</sub>),这里的x<sub>i</sub>,y<sub>i</sub> $\in$ {0,1}</li><li>使用<strong>Dot Product</strong> 来计算query和文档的相似度<br>Sim(q,d)=q*d =x<sub>i</sub>y<sub>1</sub>+…+x<sub>N</sub>y<sub>N</sub>=$\sum_{i=1}^N$x<sub>i</sub>y<sub>i</sub></li></ul></blockquote><p>举个例子:<br>Query =  “<font color="#CC0000">news about presidential campaign</font>“ </p><div class="table-container"><table><thead><tr><th>doc</th><th>content </th></tr></thead><tbody><tr><td>d1</td><td>… <font color="#CC0000">news about</font>…</td></tr><tr><td>d2</td><td>… <font color="#CC0000">news about</font> organic food <font color="#CC0000">campaign</font>…</td></tr><tr><td>d3</td><td>… <font color="#CC0000">news</font> of <font color="#CC0000">presidential campaign</font>…</td></tr><tr><td>d4</td><td><font color="#CC0000">news</font> of <font color="#CC0000">presidential campaign</font>… <font color="#CC0000">presidential</font> candidate …</td></tr><tr><td>d5</td><td><font color="#CC0000">news</font> of organic food <font color="#CC0000">campaign</font> … <font color="#CC0000">campaign</font> … <font color="#CC0000">campaign</font> … <font color="#CC0000">campaign</font> …</td></tr></tbody></table></div><p>如果让我们来根据这个query对这5个文档排序的话，一种可能的结果是<br>d4+, d3+ ,d1- ,d2- d5- (这里的顺序就是表示文档的相似度的排序，+表示正相关，-表示负相关)。<br>那如果我们使用<strong>Simplest Vecotr Model</strong>来对文档来打分，结果会怎么样？<br>Query =  “<font color="#CC0000">news about presidential campaign</font>“</p><div class="table-container"><table><thead><tr><th>doc</th><th>content </th></tr></thead><tbody><tr><td>d1</td><td>… <font color="#CC0000">news about</font>…</td></tr><tr><td>d3</td><td>… <font color="#CC0000">news</font> of <font color="#CC0000">presidential campaign </font></td></tr></tbody></table></div><p>这里V={news, about, presidential, campaign,food …},那么我们可以通过<strong>Bag of words</strong> 和<strong>Bit Vector</strong> 来表示query和文档d1,d3,并且计算对应的similarity (通过下面的例子我们可以看到词袋模型没有按照文章中单词的顺序进行排序，而是根据V中所有的词的顺序来进行赋值的，有就是1，没有就是0))<br>q=(     1,   1,     1,      1,      0, …)<br>d1=(    1,   1,     0,      0,      0, …) , <font color="#CC0000">f(q,d1)= 1x1+1x1+1x0+1x0+0x0+ .. =2 </font><br>d3=(    1,   0,     1,      1,      0, …),  <font color="#CC0000">f(q,d1)=1x1+1x0+1x1+1x1+0x0+ .. =3 </font><br>按照同样的方法，我们计算出所有文档的分数</p><div class="table-container"><table><thead><tr><th>doc</th><th>content</th><th>score</th></tr></thead><tbody><tr><td>d1</td><td>… <font color="#CC0000">news about</font>…</td><td>f(q,d1)=2</td></tr><tr><td>d2</td><td>… <font color="#CC0000">news about</font> organic food <font color="#CC0000">campaign</font>…</td><td>f(q,d2)=3</td></tr><tr><td>d3</td><td>… <font color="#CC0000">news</font> of <font color="#CC0000">presidential campaign</font>…</td><td>f(q,d3)=3</td></tr><tr><td>d4</td><td><font color="#CC0000">news</font> of <font color="#CC0000">presidential campaign</font>… <font color="#CC0000">presidential</font> candidate …</td><td>f(q,d4)=3</td></tr><tr><td>d5</td><td><font color="#CC0000">news</font> of organic food <font color="#CC0000">campaign</font> … <font color="#CC0000">campaign</font> … <font color="#CC0000">campaign</font> … <font color="#CC0000">campaign</font> …</td><td>f(q,d5)=2</td></tr></tbody></table></div><p>最终的按照score排序的结果为 (d4,d3,d2) (d1,d5) [因为d4,d3,d2 分数一样，所以部分前后， d1,d5同样如此]],貌似<strong>Simplest Vector Model</strong> 反映了一些文档和query的相关程度，但是效果没有那么的达到预期。<br>如果我们仔细会想<strong>Bit Vector</strong> 就会发现，很多信息在生成query/文档向量的时候已经被丢掉了(例如词频)，那么如果我们加上这些信息<strong>Simplest Vector Model</strong> 是不是会好很多呢? 我们将下一篇详细介绍<strong>Vector Space Model</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Text-Retrieval-and-Search-Engines学习笔记-二&quot;&gt;&lt;a href=&quot;#Text-Retrieval-and-Search-Engines学习笔记-二&quot; class=&quot;headerlink&quot; title=&quot;Text Retrieval and Search Engines学习笔记(二)&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#0077bb&quot;&gt;Text Retrieval and Search Engines学习笔记(二)&lt;/font&gt;&lt;/h1&gt;&lt;p&gt;这篇文章是继上一篇&lt;a href=&quot;https://www.fengqinglei.top/2019/10/09/text-retrieval-and-search-engines-1/&quot;&gt;Text Retrieval and Search Engines学习笔记(一)&lt;/a&gt; 的后续部分，这一篇我们重点介绍如何定义和计算&lt;strong&gt;f(q,d)&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;Text-Retrieval-Methods&quot;&gt;&lt;a href=&quot;#Text-Retrieval-Methods&quot; class=&quot;headerlink&quot; title=&quot;Text Retrieval Methods&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#0077bb&quot;&gt;Text Retrieval Methods&lt;/font&gt;&lt;/h2&gt;&lt;p&gt;首先，我们得知道如何设计一个排序方法，这里我们可以列举一个好的排序方法都有那些特征或者属性&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;关于Query :q=q&lt;sub&gt;1&lt;/sub&gt;,…,q&lt;sub&gt;m&lt;/sub&gt;, q&lt;sub&gt;i&lt;/sub&gt; $\in$ V&lt;/li&gt;
&lt;li&gt;关于Document: d&lt;sub&gt;i&lt;/sub&gt;=d&lt;sub&gt;i1&lt;/sub&gt;,…,d&lt;sub&gt;ij&lt;/sub&gt;, d&lt;sub&gt;ij&lt;/sub&gt; $\in$ V&lt;/li&gt;
&lt;li&gt;排序方法： f(q,d)$\in$R (这里表示排序方法的值在实数域，说人话就是可以取任意实数)&lt;/li&gt;
&lt;li&gt;一个好的排序方法必须将相关的文档排在不相关的文档之前,那么问题来了，我们如何衡量query和document的相关的似然度呢？ &lt;/li&gt;
&lt;li&gt;我们必须给排序模型/方法下一个明确的定义，并且这个定义还是可以明确计算的(说白了就是能够以数学公式的方式定义出来，我们可以通过数学公式计算出相关度)
    
    </summary>
    
    
      <category term="NLP" scheme="https://www.fengqinglei.top/tags/NLP/"/>
    
      <category term="Text Retrieval" scheme="https://www.fengqinglei.top/tags/Text-Retrieval/"/>
    
      <category term="Vector Space Model" scheme="https://www.fengqinglei.top/tags/Vector-Space-Model/"/>
    
      <category term="Search Engine" scheme="https://www.fengqinglei.top/tags/Search-Engine/"/>
    
      <category term="Probabilistic Model" scheme="https://www.fengqinglei.top/tags/Probabilistic-Model/"/>
    
  </entry>
  
  <entry>
    <title>Text Retrieval and Search Engines 1</title>
    <link href="https://www.fengqinglei.top/2019/10/09/text-retrieval-and-search-engines-1/"/>
    <id>https://www.fengqinglei.top/2019/10/09/text-retrieval-and-search-engines-1/</id>
    <published>2019-10-09T11:58:38.000Z</published>
    <updated>2019-10-11T13:11:06.663Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Text-Retrieval-and-Search-Engines学习笔记-一"><a href="#Text-Retrieval-and-Search-Engines学习笔记-一" class="headerlink" title="Text Retrieval and Search Engines学习笔记(一)"></a><font color="#0077bb">Text Retrieval and Search Engines学习笔记(一)</font></h1><p>这篇文章主要是记录了学习Coursera上的课程<a href="https://www.coursera.org/learn/text-retrieval/home/welcome" target="_blank" rel="noopener">Text Retrieval and Search Engines</a>的一些笔记和个人的理解,这个课程总体来说比较偏理论，虽然实战非常重要，但是有的时候我们也需要学一些理论知识，这样我们才可以慢慢的<strong>知其然，并且知其所以然</strong>。</p><h2 id="课程大纲"><a href="#课程大纲" class="headerlink" title="课程大纲"></a><font color="#0077bb">课程大纲</font></h2><blockquote><ul><li>Natural Language Content Analysis</li><li>Text Access</li><li>Text Retrieval Problem</li><li>Text Retrieval Methods</li><li>Vector Space Model</li><li>System Implementation</li><li>Evaluation</li><li>Probabilistic Model</li><li>Feedback</li><li>Web Search</li><li>Recommendation<a id="more"></a><img src="https://s2.ax1x.com/2019/10/05/uyjSp9.png" alt="course.png"><h2 id="Natural-Language-Content-Analysis"><a href="#Natural-Language-Content-Analysis" class="headerlink" title="Natural Language Content Analysis"></a><font color="#0077bb">Natural Language Content Analysis</font></h2></li><li>自然语言处理是啥?<br>百度百科对自然语言的解释是:自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。自然语言处理是一门融语言学、计算机科学、数学于一体的科学。因此，这一领域的研究将涉及自然语言，即人们日常使用的语言，所以它与语言学的研究有着密切的联系，但又有重要的区别。自然语言处理并不是一般地研究自然语言，而在于研制能有效地实现自然语言通信的计算机系统，特别是其中的软件系统。因而它是计算机科学的一部分。<br>说人话就是<strong>用机器处理人类的语言</strong>(这里的语言可以是说的，写的等等))</li><li>NLP 的例子<br>常见的nlp问题有<strong>POS</strong>,<strong>Syntatics Analysis</strong>,<strong>Semantic Analysis</strong> 等等。<br><img src="https://s2.ax1x.com/2019/10/05/uyHGtA.png" alt="nlp_example"></li><li>NLP的现状和难题<br>现在的机器学习和深度学习方法或者crf等算法在分词，机器翻译，情感分析，词性标注等问题上都有很好的表现，但是一般都是在特定领域上的表现比较好，并且这还是基于大量的人工标注或者大量的语料库的情况下，虽然最终的准确率或者各种指标都是97%甚至99%，但是自然语言处理是非常难达到100%的完美的，即使在某个特定的领域，因为有的时候甚至人也很难达到100%，比如3个人做词性标注，同一个输入，标出不同的结果非常常见，在消除歧义等任务上这种情况就更加常见了，另外在深度语义理解上NLP现有的技术也很难达到精准，但这些都不影响我们对NLP技术的学习和研究，随着技术的发展，这些问题在今后或者未来的某天一定会得到更好的解决</li><li>自然语言处理和信息检索的结合<br>了解搜索引擎历史的人都知道，很久以前的搜索引擎原理并不是倒排索引，实际上是根据用户输入的关键词到所有的文章中找的，这也是为什么很多在看老的美国大片到某个系统查询的时候输入的内容带大小写的，但是现在大家在用baidu或者google检索的时候很少有人关注某个单词的大小写(机器翻译有的时候会关注)，是因为现在的搜索引擎都是基于倒排索引的原理，英文有与生俱来的分词界线，但是中文没有(当然英文有其他的问题，例如stemming/lemmatization)，这些分词，词性标注等NLP任务都是信息检索中不可或缺的要素。<h2 id="Text-Access"><a href="#Text-Access" class="headerlink" title="Text Access"></a><font color="#0077bb">Text Access</font></h2>这个章节的内容是比较简单的，主要是讲解了文本信息系统是如何帮助用户获得相关的文本信息的,这里讲一下信息获取的两种模式</li><li>pull(拉取)<br>顾名思义，这里用户掌握主动权，可以用户查询或者浏览的方式进行信息的获取</li></ul></blockquote><div class="table-container"><table><thead><tr><th>获取信息的方式</th><th>说明</th></tr></thead><tbody><tr><td>Querying(查询)</td><td>这个是最常见的模式，比如大家到百度或者google上使用关键词查询</td></tr><tr><td>Browsing(浏览)</td><td>这个也是比较常见的，基本上当你不知道买啥的时候去淘宝上瞎逛就是浏览模式</td></tr></tbody></table></div><blockquote><ul><li>push(推送)<br>这种模式下，系统占有主动权，系统可以通过对用户profile或者用户的行为产生一定的“理解”，将用户可能想要的信息推送给用户（类似电商更具购买记录推送类似商品，或者类似用户推荐商品）</li></ul></blockquote><h2 id="Text-Retrieval-Problem"><a href="#Text-Retrieval-Problem" class="headerlink" title="Text Retrieval Problem"></a><font color="#0077bb">Text Retrieval Problem</font></h2><blockquote><ul><li>Text Retrieval 是什么<br>文本检索应该可以说是<strong>Information Retrieval</strong>的一种特殊情况把，说白就是收集现有的文本信息存储到搜索引擎中，根据用户给定的检索语句，搜索引擎返回<strong>相关</strong>的文档给用户。</li><li>Text Retrieval(TR)和数据库检索的有什么区别</li></ul></blockquote><div class="table-container"><table><thead><tr><th>-/-</th><th>文本检索</th><th>数据库检索</th></tr></thead><tbody><tr><td>信息结构</td><td>非结构化，自由结构的文本</td><td>结构化数据</td></tr><tr><td>检索方式</td><td>有歧义的，非完整的</td><td>完整的，带有语义定义的</td></tr><tr><td>返回方式</td><td>有相关性的文档</td><td>完全匹配到的结果</td></tr></tbody></table></div><p>TR(Text Retrieval) 是经验性的问题，我们很难在数学上证明一个方法比另外一个方法好，并且必须依赖经验性的评估。</p><blockquote><ul><li>Text Retrieval 的定义<br>虽然我们没法使用数学公式给出100%的定义，但是我们依然可以在某种成都上给Text Retrieval下定义。</li></ul></blockquote><div class="table-container"><table><thead><tr><th>术语</th><th>定义</th></tr></thead><tbody><tr><td>Vocabulary(词汇):</td><td>V={W<sub>1</sub>,W<sub>2</sub>,W<sub>3</sub>,W<sub>4</sub>….W<sub>N</sub>}, 这里W<sub>i</sub> 表示某个词</td></tr><tr><td>Query(查询条件):</td><td>q=q<sub>1</sub>,…,q<sub>m</sub>, q<sub>i</sub> $\in$ V</td></tr><tr><td>Document(文档):</td><td>d<sub>i</sub>=d<sub>i1</sub>,…,d<sub>ij</sub>, d<sub>ij</sub> $\in$ V</td></tr><tr><td>Collection(集合):</td><td>C={d<sub>i</sub>,…, d<sub>M</sub>}，所有的文档组成了一个集合</td></tr><tr><td>Set of relevant documents(相关文档):</td><td>R(q) $\subseteq$ C，相关文档是所有的文档的一个子集</td></tr><tr><td>Task(任务):</td><td>计算文档相关度R<sup>,</sup>(q),这里的R<sup>,</sup>(q)其实是R(q)的一个近似表示，前面说了我们没法给出100%的数学定义，但是我们可以给出一个近似的定义(可以度量并且有效的定义))</td></tr></tbody></table></div><h2 id="如何计算R-q"><a href="#如何计算R-q" class="headerlink" title="如何计算R,(q)"></a><font color="#0077bb">如何计算R<sup>,</sup>(q)</font></h2><p>由于Text Retrieval的目标是找到相关的文档，那么如何定义相关，我们则需要通过完成R<sup>,</sup>(q)的计算，这里给出两种可行的方法.(方法有很多，不仅仅局限于这两种))</p><blockquote><ul><li>策略(一)：文档选择方式<br>R<sup>,</sup>(q)={d$\in$C|f(d,q)=1},这里的f(d,q)$\in${0,1}是我们定义的一个方法，这个方法取值要么为0要么为1 （二元分类器），说白了就是要么相关(1),要不不相关(0)</li><li>策略(二)：文档排序<br>R<sup>,</sup>(q)={d$\in$C|f(d,q)&gt;$\theta$}, 这里的f(d,q)$\in$R是一个度量的方法，这里的$\theta$}是一取决于用户的选择，此时系统只需要决定是否某个文档比另外的文档<strong>更相关</strong>（相对相关度）<br>当然通过这两种方式计算R<sup>,</sup>(q)都是有效的，但是那种方法更加切合实际？我们可以通过以下几个点进行分析。<br><img src="https://s2.ax1x.com/2019/10/08/ufarWQ.png" alt="Document_selection_vs_ranking.png"></li><li>二元分类其很有可能不太准确，因为很难区分一个文档到底是相关还是不想关，可能我们设定的条件会约束太强，也有可能约束太弱，那么或多或少的导致会将相关的文档会遗漏或者不相关的文档会被返回给最终用户。</li><li>即使我们在分类的时候将所有的结果都正确的放置在正确的分类上，但是实际上所有的文档的相关性不是都是一样的，不同的文档的相关程度是不尽相同的。所以我们需要设置一定的优先级。</li><li>综上两个观点，我们认为ranking是一个更好的解决方案。<h2 id="ranking方式的理论论证"><a href="#ranking方式的理论论证" class="headerlink" title="ranking方式的理论论证"></a><font color="#0077bb">ranking方式的理论论证</font></h2><a href="https://www.emerald.com/insight/content/doi/10.1108/eb026647/full/html" target="_blank" rel="noopener">The probability ranking principle in IR</a> 原文是:<br>Returning a ranked list of documents in descending order of probability that a document is relevant to the query is the optimal strategy under the following two assumptions:<br>– The utility of a document (to a user) is <strong>independent</strong> of the utility of any other document<br>– A user would browse the results <strong>sequentially</strong><br>简单来说就是:文本检索引擎按照文档和query相关的概率降序排列是一个最优策略，当然这个最有策略基于以下两个前提</li><li>某一个文档的作用和其他文档的作用是互不相关的</li><li>用户会按照结果的顺序来浏览结果<br>但是实际上这两个假设并不是100%都是成立的，两个文档可能是相似的，所以肯定不是100%完全独立的，而且用户可能会跳着看一些结果，但是，即使这些假设都不是100%成立的，按照文档和query相关的概率对结果进行排序在大部分的场景下仍然是一种合理的做法。</li></ul></blockquote><p>至此，我们可以得出-&gt; 对文档进行排序相比对文档进行二元分类似乎是一种更加有效的解决文本检索问题的方法，前面我们也提到过，解决文档和query相关的关键在于如何计算R<sup>,</sup>(q),其实就是如何定义一个有效的f(q,d)方法。这个我会在后面的章节继续探讨。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Text-Retrieval-and-Search-Engines学习笔记-一&quot;&gt;&lt;a href=&quot;#Text-Retrieval-and-Search-Engines学习笔记-一&quot; class=&quot;headerlink&quot; title=&quot;Text Retrieval and Search Engines学习笔记(一)&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#0077bb&quot;&gt;Text Retrieval and Search Engines学习笔记(一)&lt;/font&gt;&lt;/h1&gt;&lt;p&gt;这篇文章主要是记录了学习Coursera上的课程&lt;a href=&quot;https://www.coursera.org/learn/text-retrieval/home/welcome&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Text Retrieval and Search Engines&lt;/a&gt;的一些笔记和个人的理解,这个课程总体来说比较偏理论，虽然实战非常重要，但是有的时候我们也需要学一些理论知识，这样我们才可以慢慢的&lt;strong&gt;知其然，并且知其所以然&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;课程大纲&quot;&gt;&lt;a href=&quot;#课程大纲&quot; class=&quot;headerlink&quot; title=&quot;课程大纲&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#0077bb&quot;&gt;课程大纲&lt;/font&gt;&lt;/h2&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Natural Language Content Analysis&lt;/li&gt;
&lt;li&gt;Text Access&lt;/li&gt;
&lt;li&gt;Text Retrieval Problem&lt;/li&gt;
&lt;li&gt;Text Retrieval Methods&lt;/li&gt;
&lt;li&gt;Vector Space Model&lt;/li&gt;
&lt;li&gt;System Implementation&lt;/li&gt;
&lt;li&gt;Evaluation&lt;/li&gt;
&lt;li&gt;Probabilistic Model&lt;/li&gt;
&lt;li&gt;Feedback&lt;/li&gt;
&lt;li&gt;Web Search&lt;/li&gt;
&lt;li&gt;Recommendation
    
    </summary>
    
    
      <category term="NLP" scheme="https://www.fengqinglei.top/tags/NLP/"/>
    
      <category term="Text Retrieval" scheme="https://www.fengqinglei.top/tags/Text-Retrieval/"/>
    
      <category term="Vector Space Model" scheme="https://www.fengqinglei.top/tags/Vector-Space-Model/"/>
    
      <category term="Search Engine" scheme="https://www.fengqinglei.top/tags/Search-Engine/"/>
    
      <category term="Probabilistic Model" scheme="https://www.fengqinglei.top/tags/Probabilistic-Model/"/>
    
  </entry>
  
  <entry>
    <title>玩转Solr源码之(三)Solr源码Deploy</title>
    <link href="https://www.fengqinglei.top/2019/10/03/solr-source-code-deploy/"/>
    <id>https://www.fengqinglei.top/2019/10/03/solr-source-code-deploy/</id>
    <published>2019-10-02T23:57:04.000Z</published>
    <updated>2019-10-03T08:30:56.061Z</updated>
    
    <content type="html"><![CDATA[<h1 id="玩转Solr源码之—Solr源码Deploy"><a href="#玩转Solr源码之—Solr源码Deploy" class="headerlink" title="玩转Solr源码之—Solr源码Deploy"></a><font color="#0077bb">玩转Solr源码之—Solr源码Deploy</font></h1><p>这篇文章是<strong>玩转Solr源码</strong>系列的第三篇，紧接着上一篇的<a href="https://www.fengqinglei.top/2019/10/01/solr-source-code-debug/">源码Deug</a>。如果你已经修改好了源码，并且调试ok，想要将源码打包后分发给同时或者其他项目引用，那么这边文章一定能够帮助你。<br><a id="more"></a></p><h2 id="不到万不得己，别直接改源代码"><a href="#不到万不得己，别直接改源代码" class="headerlink" title="不到万不得己，别直接改源代码"></a><font color="#0077bb">不到万不得己，别直接改源代码</font></h2><p>一般而言，如果将Solr/Elasticsearch应用于企业级开发，Solr原生的功能或多或少都不能100%的满足企业的业务需求(客户的需求都是比较变态的),这也使得我们有的时候不得不通过修改源代码的方式来达到我们的目的，改源码难，管理源代码更难，毕竟几万甚至几十万的行的Solr源码，你只动了其中一个类中的某一个方法，结果为了管理，你需要专门搞个git仓库，然后还要定义好版本号，放到nexus仓库给其他组员或者其他项目引用，改代码可能花了你一个小时，但是管理这些代码可能需要让你忙活一个上午。所以不到万不得已尽量通过继承/实现等方式来修改源码，这样在版本升级的时候，工作量会小很多。否则的话，干过的人都知道很痛苦，特别是上一个改了源码的人已经离职了。<br><img src="https://s2.ax1x.com/2019/10/03/uwD7dI.jpg" alt="uwD7dI.jpg"></p><h2 id="从源码到Nexus"><a href="#从源码到Nexus" class="headerlink" title="从源码到Nexus"></a><font color="#0077bb">从源码到Nexus</font></h2><p>笔者所在的公司Java开发使用的构建和依赖管理工具是Maven,仓库的话使用的是自建的nexus,我相信这也是大部分公司的模式，当然也有用Gradle，这里不比较两个工具的好坏，能完成开发，高效率并且使用的顺手的都是好工具。笔者这里以maven+ nexus为例。</p><h3 id="安装Nexus"><a href="#安装Nexus" class="headerlink" title="安装Nexus"></a><font color="#0077bb">安装Nexus</font></h3><p>大部分情况下，nexus仓库这种工作都是交给运维去搞的，一般开发只需要知道如何使用就行，如果你对安装nexus没有任何兴趣，那么这部分可以选择跳过。<br>为了方便演示，这里笔者使用了docker进行安装和部署nexus，流程比较简单，几行命令就行了,这里以<a href="https://hub.docker.com/r/sonatype/nexus/" target="_blank" rel="noopener">nexus2</a>为例子.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull sonatype/nexus</span><br><span class="line">docker run -d -p 8081:8081 --name nexus-oss sonatype/nexus</span><br></pre></td></tr></table></figure></p><p>打开浏览器输入<strong><a href="http://127.0.0.1:8081/nexus" target="_blank" rel="noopener">http://127.0.0.1:8081/nexus</a></strong>就可以看到nexuys界面啦，默认的登陆用户名和密码为admin,admin123<br><img src="https://s2.ax1x.com/2019/10/03/uwRhqS.png" alt="Nexus2"></p><h3 id="使用ant生成maven-artifacts并上传"><a href="#使用ant生成maven-artifacts并上传" class="headerlink" title="使用ant生成maven artifacts并上传"></a><font color="#0077bb">使用ant生成maven artifacts并上传</font></h3><p>Solr中的源码已经支持生成maven artifacets并且上传到自定义的仓库中，简单的命令为<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ant -Dversion=my-special-version -Dm2.repository.id=my-repo-id \</span><br><span class="line">          -Dm2.repository.url=https://example.org/my/repo \</span><br><span class="line">          generate-maven-artifacts</span><br></pre></td></tr></table></figure></p><p>这里解释下参数的含义</p><div class="table-container"><table><thead><tr><th>变量名</th><th>解释</th></tr></thead><tbody><tr><td>my-special-version</td><td>指定版本号，这个大家根据需要可以自定义，但是还是需要一定的命名规范（下面会讲到）</td></tr><tr><td>my-repo-id</td><td>表示nexus仓库的id，名称一般都是自定义的</td></tr><tr><td>m2.repository.url</td><td>表示nexuys仓库的地址，笔者这里的地址就是<strong><a href="http://127.0.0.1:8081/nexus/content/repositories/releases/" target="_blank" rel="noopener">http://127.0.0.1:8081/nexus/content/repositories/releases/</a></strong></td></tr></tbody></table></div><p>具体的可以参考文档<a href="https://github.com/apache/lucene-solr/blob/master/dev-tools/maven/README.maven" target="_blank" rel="noopener">Lucene/Solr Maven build instructions</a>。<br>到这里大家基本上已经知道如是将修改过后的solr源代码打包并且上传maven了吧，废话不多说，直接上命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[fql@localhost solr-7.7.2]$ ant -Dversion=TEST -Dm2.repository.id=nexus -Dm2.repository.url=http://127.0.0.1:8081/nexus/content/repositories/releases/ generate-maven-artifacts</span><br><span class="line">Buildfile: /home/fql/IdeaProjects/solr-7.7.2/build.xml</span><br><span class="line"></span><br><span class="line">BUILD FAILED</span><br><span class="line">/home/fql/IdeaProjects/solr-7.7.2/build.xml:21: The following error occurred <span class="keyword">while</span> executing this line:</span><br><span class="line">/home/fql/IdeaProjects/solr-7.7.2/lucene/common-build.xml:63: If you pass -Dversion=... to <span class="built_in">set</span> a release version, it must match <span class="string">"7.7.2"</span>, optionally followed by a suffix (e.g., <span class="string">"-SNAPSHOT"</span>).</span><br><span class="line"></span><br><span class="line">Total time: 0 seconds</span><br></pre></td></tr></table></figure></p><p>擦，&lt;一顿操作猛如虎，定睛一看原地杵&gt;,原来version的名称海必须匹配<strong>7.7.2</strong>,好吧，再来<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[fql@localhost solr-7.7.2]$ ant -Dversion=7.7.2-TEST -Dm2.repository.id=nexus -Dm2.repository.url=http://127.0.0.1:8081/nexus/content/repositories/releases/ generate-maven-artifacts</span><br><span class="line">Buildfile: /home/fql/IdeaProjects/solr-7.7.2/build.xml</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">[artifact:deploy] Error deploying artifact <span class="string">'org.apache.lucene:lucene-solr-grandparent:pom'</span>: Error deploying artifact: Failed to transfer file: http://127.0.0.1:8081/nexus/content/repositories/releases/org/apache/lucene/lucene-solr-grandparent/7.7.2-TEST/lucene-solr-grandparent-7.7.2-TEST.pom. Return code is: 401</span><br><span class="line"></span><br><span class="line">BUILD FAILED</span><br><span class="line">/home/fql/IdeaProjects/solr-7.7.2/build.xml:209: The following error occurred <span class="keyword">while</span> executing this line:</span><br><span class="line">/home/fql/IdeaProjects/solr-7.7.2/lucene/build.xml:404: The following error occurred <span class="keyword">while</span> executing this line:</span><br><span class="line">/home/fql/IdeaProjects/solr-7.7.2/lucene/common-build.xml:656: Error deploying artifact <span class="string">'org.apache.lucene:lucene-solr-grandparent:pom'</span>: Error deploying artifact: Failed to transfer file: http://127.0.0.1:8081/nexus/content/repositories/releases/org/apache/lucene/lucene-solr-grandparent/7.7.2-TEST/lucene-solr-grandparent-7.7.2-TEST.pom. Return code is: 401</span><br><span class="line">Total time: 8 minutes 53 seconds</span><br></pre></td></tr></table></figure></p><p><strong>Return code is: 401</strong>,貌似权限不对，确实命令中没有传任何用户名和密码的信息，这里通过<strong>generate-maven-artifacts</strong>定位到solr-7.7.2/lucene/common-build.xml 文件中的<strong>m2-deploy</strong>(第646行)，并且在其下面的<strong>remoteRepository</strong>添加<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">authentication</span> <span class="attr">username</span>=<span class="string">"admin"</span> <span class="attr">password</span>=<span class="string">"admin123"</span>/&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- admin 和admin123 就是nexus的默认用户名和密码--&gt;</span></span><br></pre></td></tr></table></figure></p><p>重新执行命令我们就可以看到项目已经成功的上传到了本地的nexus(看起来一行代码搞定的问题，确实让你琢磨了一个上午)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[fql@localhost solr-7.7.2]$ ant -Dversion=7.7.2-TEST -Dm2.repository.id=nexus -Dm2.repository.url=http://192.168.34.128:8081/nexus/content/repositories/releases/ generate-maven-artifacts</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">[artifact:deploy] [INFO] Uploading repository metadata <span class="keyword">for</span>: <span class="string">'artifact org.apache.solr:solr-velocity'</span></span><br><span class="line">[artifact:deploy] Uploading: org/apache/solr/solr-velocity/7.7.2-TEST/solr-velocity-7.7.2-TEST-sources.jar to repository nexus at http://192.168.34.128:8081/nexus/content/repositories/releases/</span><br><span class="line">[artifact:deploy] Transferring 31K from nexus</span><br><span class="line">[artifact:deploy] Uploaded 31K</span><br><span class="line">[artifact:deploy] Uploading: org/apache/solr/solr-velocity/7.7.2-TEST/solr-velocity-7.7.2-TEST-javadoc.jar to repository nexus at http://192.168.34.128:8081/nexus/content/repositories/releases/</span><br><span class="line">[artifact:deploy] Transferring 64K from nexus</span><br><span class="line">[artifact:deploy] Uploaded 64K</span><br><span class="line">[artifact:install] [INFO] Installing /home/fql/IdeaProjects/solr-7.7.2/solr/build/solr.tgz.unpacked/solr-7.7.2-TEST/dist/solr-velocity-7.7.2-TEST.jar to /home/fql/.m2/repository/org/apache/solr/solr-velocity/7.7.2-TEST/solr-velocity-7.7.2-TEST.jar</span><br><span class="line">[artifact:install] [INFO] Installing /home/fql/IdeaProjects/solr-7.7.2/solr/build/contrib/solr-velocity/solr-velocity-7.7.2-TEST-src.jar to /home/fql/.m2/repository/org/apache/solr/solr-velocity/7.7.2-TEST/solr-velocity-7.7.2-TEST-sources.jar</span><br><span class="line">[artifact:install] [INFO] Installing /home/fql/IdeaProjects/solr-7.7.2/solr/build/contrib/solr-velocity/solr-velocity-7.7.2-TEST-javadoc.jar to /home/fql/.m2/repository/org/apache/solr/solr-velocity/7.7.2-TEST/solr-velocity-7.7.2-TEST-javadoc.jar</span><br><span class="line">[artifact:install] [INFO] Installing /home/fql/IdeaProjects/solr-7.7.2/solr/build/contrib/solr-velocity/solr-velocity-7.7.2-TEST-src.jar to /home/fql/.m2/repository/org/apache/solr/solr-velocity/7.7.2-TEST/solr-velocity-7.7.2-TEST-sources.jar</span><br><span class="line">[artifact:install] [INFO] Installing /home/fql/IdeaProjects/solr-7.7.2/solr/build/contrib/solr-velocity/solr-velocity-7.7.2-TEST-javadoc.jar to /home/fql/.m2/repository/org/apache/solr/solr-velocity/7.7.2-TEST/solr-velocity-7.7.2-TEST-javadoc.jar</span><br><span class="line">BUILD SUCCESSFUL</span><br><span class="line">Total time: 6 minutes 37 seconds</span><br></pre></td></tr></table></figure></p><p>打开浏览器<strong><a href="http://127.0.0.1:8081/nexus/content/repositories/releases/org/apache/lucene/" target="_blank" rel="noopener">http://127.0.0.1:8081/nexus/content/repositories/releases/org/apache/lucene/</a></strong> 我们就可以看见solr相关的jar包pom等信息已经上传成功<br><img src="https://s2.ax1x.com/2019/10/03/uwLkQg.png" alt="nexus_solr"></p><h3 id="爬坑小技巧"><a href="#爬坑小技巧" class="headerlink" title="爬坑小技巧"></a><font color="#0077bb">爬坑小技巧</font></h3><p>看似简单的工作，实际操作起来整的耗费了很长的时间，关键是关于<strong>authentication</strong>的那部分google了好久发现没一个人提。为了防止大家再次爬坑，这里给大家分享两个知识点/小技巧</p><blockquote><ul><li>解决ant idea 下载比较慢的问题<br>大家在导入Solr源码项目的时候可能已经发现了，(<strong>ant idea</strong>)整个过程非常的慢,笔者更是等了一个下午才构建好，正常的开发中我们不可能等这么久，这里可能有人说使用maven默认的仓库在海外导致的，我们使用aliyun的仓库就可行了(笔者尝试了，不行，不知道为什么阿里云下载的时候没有http状态码，导致ivy认为仓库不可用)，这里笔者使用了腾讯云的仓库(<a href="http://mirrors.cloud.tencent.com/nexus/repository/maven-public/),企鹅貌似比阿里守规范。。,具体的改动点为，修改**solr-7.7.2/lucene/default-nested-ivy-settings.xml**配置文件，添加自定义resolver" target="_blank" rel="noopener">http://mirrors.cloud.tencent.com/nexus/repository/maven-public/),企鹅貌似比阿里守规范。。,具体的改动点为，修改**solr-7.7.2/lucene/default-nested-ivy-settings.xml**配置文件，添加自定义resolver</a> (+表示在源文件中增加一行，-表示删除源文件中的某一行)<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">resolvers</span>&gt;</span></span><br><span class="line"> +   <span class="tag">&lt;<span class="name">ibiblio</span> <span class="attr">name</span>=<span class="string">"tecent"</span> <span class="attr">root</span>=<span class="string">"http://mirrors.cloud.tencent.com/nexus/repository/maven-public/"</span>  <span class="attr">m2compatible</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ibiblio</span> <span class="attr">name</span>=<span class="string">"sonatype-releases"</span> <span class="attr">root</span>=<span class="string">"https://oss.sonatype.org/content/repositories/releases"</span> <span class="attr">m2compatible</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ibiblio</span> <span class="attr">name</span>=<span class="string">"maven.restlet.com"</span> <span class="attr">root</span>=<span class="string">"https://maven.restlet.com"</span> <span class="attr">m2compatible</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ibiblio</span> <span class="attr">name</span>=<span class="string">"releases.cloudera.com"</span> <span class="attr">root</span>=<span class="string">"https://repository.cloudera.com/cloudera/libs-release-local"</span> <span class="attr">m2compatible</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">-    <span class="tag">&lt;<span class="name">resolver</span> <span class="attr">ref</span>=<span class="string">"main"</span>/&gt;</span></span><br><span class="line">+    <span class="tag">&lt;<span class="name">resolver</span> <span class="attr">ref</span>=<span class="string">"tecent"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">resolver</span> <span class="attr">ref</span>=<span class="string">"maven.restlet.com"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">resolver</span> <span class="attr">ref</span>=<span class="string">"sonatype-releases"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">resolver</span> <span class="attr">ref</span>=<span class="string">"releases.cloudera.com"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">chain</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">resolvers</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul></blockquote><p>备份并删除~/.ivy2/cache,否则会使用缓存，重新执行命令(<strong>ant idea</strong>)之后你会发现还是会卡在resolve,但是下载jar包的速度变快了，笔者google了半天发现没有答案，猜想可能是多个resolve 导致的，尝试注释其他的机器resolver,具体的改动为<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">-    <span class="tag">&lt;<span class="name">resolver</span> <span class="attr">ref</span>=<span class="string">"main"</span>/&gt;</span></span><br><span class="line">+    <span class="tag">&lt;<span class="name">resolver</span> <span class="attr">ref</span>=<span class="string">"tecent"</span>/&gt;</span></span><br><span class="line">+   <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">    &lt;resolver ref="maven.restlet.com" /&gt;</span></span><br><span class="line"><span class="comment">    &lt;resolver ref="sonatype-releases" /&gt;</span></span><br><span class="line"><span class="comment">    &lt;resolver ref="releases.cloudera.com"/&gt;</span></span><br><span class="line"><span class="comment">+   --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">chain</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">resolvers</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>删除~/.ivy2/cache ,重新执行命令(<strong>ant idea</strong>)之后，果然速度快了很多,至此，慢的问题我们也解决了，简直💯。(使用默认的话执行需要40分钟，改进之后20分钟即可)</p><blockquote><ul><li>如何定位到<strong>authentication</strong><br>虽然解决<strong>401</strong>这个问题只需要一行代码就行了，但是找到这行代码笔者确实花了很长的时间，最终我找到了关于<a href="https://maven.apache.org/ant-tasks/reference.html#remoteRepository" target="_blank" rel="noopener">remoteRepository</a>的定义才找到<strong>authentication</strong>(一看名字就知道这货是用来传用户名和密码的),最终在文档中定位了其配置在(<a href="http://maven.apache.org/ref/3.6.2/maven-settings/settings.html#class_server)，最终经过一番尝试才成功，太坑了。" target="_blank" rel="noopener">http://maven.apache.org/ref/3.6.2/maven-settings/settings.html#class_server)，最终经过一番尝试才成功，太坑了。</a><br>当然还有一种方法，就是下载ant的源码看在源码中这个case 到底是如何执行了<strong>应该</strong>也能找到这个解法</li></ul></blockquote><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><font color="#0077bb">总结</font></h2><p>到这里玩转Solr源码系列就完全结束了，虽然内容不多，但是全是干货(毕竟是笔者一步一个坑爬过来的)。如果你对该系列有补充或者更好的意见可以联系Email:fengqingleiyue@163.com<br>最后来碗鸡汤:&lt;<strong>你能走多远,取决于你填坑能力有多强</strong>&gt;<br><img src="https://s2.ax1x.com/2019/10/03/uwX5Zj.jpg" alt="uwX5Zj.jpg"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;玩转Solr源码之—Solr源码Deploy&quot;&gt;&lt;a href=&quot;#玩转Solr源码之—Solr源码Deploy&quot; class=&quot;headerlink&quot; title=&quot;玩转Solr源码之—Solr源码Deploy&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#0077bb&quot;&gt;玩转Solr源码之—Solr源码Deploy&lt;/font&gt;&lt;/h1&gt;&lt;p&gt;这篇文章是&lt;strong&gt;玩转Solr源码&lt;/strong&gt;系列的第三篇，紧接着上一篇的&lt;a href=&quot;https://www.fengqinglei.top/2019/10/01/solr-source-code-debug/&quot;&gt;源码Deug&lt;/a&gt;。如果你已经修改好了源码，并且调试ok，想要将源码打包后分发给同时或者其他项目引用，那么这边文章一定能够帮助你。&lt;br&gt;
    
    </summary>
    
    
      <category term="Solr" scheme="https://www.fengqinglei.top/tags/Solr/"/>
    
      <category term="源码" scheme="https://www.fengqinglei.top/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="Deploy" scheme="https://www.fengqinglei.top/tags/Deploy/"/>
    
      <category term="部署" scheme="https://www.fengqinglei.top/tags/%E9%83%A8%E7%BD%B2/"/>
    
      <category term="Nexus" scheme="https://www.fengqinglei.top/tags/Nexus/"/>
    
      <category term="Maven" scheme="https://www.fengqinglei.top/tags/Maven/"/>
    
  </entry>
  
  <entry>
    <title>玩转Solr源码之(二)Solr源码Debug</title>
    <link href="https://www.fengqinglei.top/2019/10/01/solr-source-code-debug/"/>
    <id>https://www.fengqinglei.top/2019/10/01/solr-source-code-debug/</id>
    <published>2019-10-01T14:19:40.000Z</published>
    <updated>2019-10-03T02:33:08.974Z</updated>
    
    <content type="html"><![CDATA[<h1 id="玩转Solr源码之—Solr源码Debug"><a href="#玩转Solr源码之—Solr源码Debug" class="headerlink" title="玩转Solr源码之—Solr源码Debug"></a><font color="#0077bb">玩转Solr源码之—Solr源码Debug</font></h1><p>这篇文章是<strong>玩转Solr源码</strong>系列的第二篇，紧接着上一篇的<a href="https://www.fengqinglei.top/2019/10/01/solr-source-code-import/">源码导入</a>，如果你还对如何将Solr源码导入到IDE还不了解的话，建议先看<strong>源码导入</strong>的部分。</p><h2 id="定位源码入口"><a href="#定位源码入口" class="headerlink" title="定位源码入口"></a><font color="#2C3E50">定位源码入口</font></h2><p>Solr 的源码入口为<strong>org.apache.solr.client.solrj.StartSolrJetty</strong>,主方法也比较简短,<br><a id="more"></a><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">( String[] args )</span> </span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="comment">//System.setProperty("solr.solr.home", "../../../example/solr");</span></span><br><span class="line"></span><br><span class="line">    Server server = <span class="keyword">new</span> Server();</span><br><span class="line">    ServerConnector connector = <span class="keyword">new</span> ServerConnector(server, <span class="keyword">new</span> HttpConnectionFactory());</span><br><span class="line">    <span class="comment">// Set some timeout options to make debugging easier.</span></span><br><span class="line">    connector.setIdleTimeout(<span class="number">1000</span> * <span class="number">60</span> * <span class="number">60</span>);</span><br><span class="line">    connector.setSoLingerTime(-<span class="number">1</span>);</span><br><span class="line">    connector.setPort(<span class="number">8983</span>);</span><br><span class="line">    server.setConnectors(<span class="keyword">new</span> Connector[] &#123; connector &#125;);</span><br><span class="line">    </span><br><span class="line">    WebAppContext bb = <span class="keyword">new</span> WebAppContext();</span><br><span class="line">    bb.setServer(server);</span><br><span class="line">    bb.setContextPath(<span class="string">"/solr"</span>);</span><br><span class="line">    bb.setWar(<span class="string">"webapp/web"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//    // START JMX SERVER</span></span><br><span class="line"><span class="comment">//    if( true ) &#123;</span></span><br><span class="line"><span class="comment">//      MBeanServer mBeanServer = ManagementFactory.getPlatformMBeanServer();</span></span><br><span class="line"><span class="comment">//      MBeanContainer mBeanContainer = new MBeanContainer(mBeanServer);</span></span><br><span class="line"><span class="comment">//      server.getContainer().addEventListener(mBeanContainer);</span></span><br><span class="line"><span class="comment">//      mBeanContainer.start();</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line">    </span><br><span class="line">    server.setHandler(bb);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      System.out.println(<span class="string">"&gt;&gt;&gt; STARTING EMBEDDED JETTY SERVER, PRESS ANY KEY TO STOP"</span>);</span><br><span class="line">      server.start();</span><br><span class="line">      <span class="keyword">while</span> (System.in.available() == <span class="number">0</span>) &#123;</span><br><span class="line">        Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      server.stop();</span><br><span class="line">      server.join();</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">      System.exit(<span class="number">100</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p><h2 id="配置Solr-Home"><a href="#配置Solr-Home" class="headerlink" title="配置Solr Home"></a><font color="#2C3E50">配置Solr Home</font></h2><p>为了能够进行源码的bug，我们需要配置好solr_home,这里我们可以直接使用官方的Solr发行包中的example来做演示（真实的开发中，一般会有自己定义好的solr_home），直接下载solr的发行包(这里以solr-7.7.2为例子)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/Documents</span><br><span class="line">curl <span class="string">"http://mirrors.tuna.tsinghua.edu.cn/apache/lucene/solr/7.7.2/solr-7.7.2.tgz"</span> -o solr-7.7.2.tgz &amp;&amp; tar -xvf solr-7.7.2.tgz</span><br><span class="line">mkdir solr_home &amp;&amp; <span class="built_in">cd</span> solr_home</span><br><span class="line">cp ~/Documents/solr-7.7.2/server/solr/solr.xml ./</span><br><span class="line">cp -r ~/Documents/solr-7.7.2/server/solr/configsets/sample_techproducts_configs ./</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"collection=TEST"</span> &gt; sample_techproducts_configs/core.properties</span><br></pre></td></tr></table></figure></p><p>这里简单解释下最后一个命令(echo “collection=TEST …”)的含义,Solr中有collection和core的概念。</p><blockquote><ul><li>Collection<br>Solr中的collection由一个或者多个core组成，一个collection对应一份独立的config，在单节点的模式下，core和collection是等价的,在集群模式下，一个collection会有多个分片(shard)组成，每个分片又可以又多个副本(replica),每个shard对应一个core</li><li>core<br>Solr中的core是一个包含index和config的运行实例<h2 id="配置StartSolrJetty"><a href="#配置StartSolrJetty" class="headerlink" title="配置StartSolrJetty"></a><font color="#2C3E50">配置StartSolrJetty</font></h2>solr中的solr_home 可以通过通过环境变量进行设置，直接上代码<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">System.setProperty(<span class="string">"solr.solr.home"</span>, <span class="string">"/home/fql/Documents/solr_home"</span>);</span><br></pre></td></tr></table></figure></li></ul></blockquote><p>还有一个地方需要改动，否则程序无法正常启动，直接上代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bb.setWar(<span class="string">"webapp/web"</span>); ==&gt; bb.setWar(<span class="string">"solr/webapp/web"</span>);</span><br></pre></td></tr></table></figure></p><p>设置完毕之后就可以启动<strong>StartSolrJetty</strong>后直接在浏览器中输入<a href="http://127.0.0.1:8983/solr就可以开始畅游solr的源码啦.![本地访问](https://s2.ax1x.com/2019/10/02/udq8Tx.png" target="_blank" rel="noopener">http://127.0.0.1:8983/solr就可以开始畅游solr的源码啦.![本地访问](https://s2.ax1x.com/2019/10/02/udq8Tx.png</a>)</p><h3 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a><font color="#2C3E50">小技巧</font></h3><p>StartSolrJetty默认的配置是没有太多的日志输出的，但是既然我们都已经开始debug solr的源代码了，还是输出更多的日志帮助我们更好的分析源码吧，同样，开启debug日志的代码也比较简单<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">System.setProperty(<span class="string">"log4j2.debug"</span>,<span class="string">"true"</span>);</span><br></pre></td></tr></table></figure></p><p>这样我们就剋有看到所有的日志啦。下一篇我们将要介绍如果将修改过的solr源码部署到公司或者个人的nexus仓库,也是本系列的最后一篇。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;玩转Solr源码之—Solr源码Debug&quot;&gt;&lt;a href=&quot;#玩转Solr源码之—Solr源码Debug&quot; class=&quot;headerlink&quot; title=&quot;玩转Solr源码之—Solr源码Debug&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#0077bb&quot;&gt;玩转Solr源码之—Solr源码Debug&lt;/font&gt;&lt;/h1&gt;&lt;p&gt;这篇文章是&lt;strong&gt;玩转Solr源码&lt;/strong&gt;系列的第二篇，紧接着上一篇的&lt;a href=&quot;https://www.fengqinglei.top/2019/10/01/solr-source-code-import/&quot;&gt;源码导入&lt;/a&gt;，如果你还对如何将Solr源码导入到IDE还不了解的话，建议先看&lt;strong&gt;源码导入&lt;/strong&gt;的部分。&lt;/p&gt;
&lt;h2 id=&quot;定位源码入口&quot;&gt;&lt;a href=&quot;#定位源码入口&quot; class=&quot;headerlink&quot; title=&quot;定位源码入口&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#2C3E50&quot;&gt;定位源码入口&lt;/font&gt;&lt;/h2&gt;&lt;p&gt;Solr 的源码入口为&lt;strong&gt;org.apache.solr.client.solrj.StartSolrJetty&lt;/strong&gt;,主方法也比较简短,&lt;br&gt;
    
    </summary>
    
    
      <category term="Solr" scheme="https://www.fengqinglei.top/tags/Solr/"/>
    
      <category term="Debug" scheme="https://www.fengqinglei.top/tags/Debug/"/>
    
      <category term="源码" scheme="https://www.fengqinglei.top/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="调试" scheme="https://www.fengqinglei.top/tags/%E8%B0%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>玩转Solr源码之(一)Solr源码导入IDE</title>
    <link href="https://www.fengqinglei.top/2019/10/01/solr-source-code-import/"/>
    <id>https://www.fengqinglei.top/2019/10/01/solr-source-code-import/</id>
    <published>2019-10-01T07:47:33.000Z</published>
    <updated>2019-10-02T13:30:57.770Z</updated>
    
    <content type="html"><![CDATA[<h1 id="玩转Solr源码之—Solr源码导入IDE"><a href="#玩转Solr源码之—Solr源码导入IDE" class="headerlink" title="玩转Solr源码之—Solr源码导入IDE"></a><font color="#0077bb">玩转Solr源码之—Solr源码导入IDE</font></h1><h2 id="源码下载"><a href="#源码下载" class="headerlink" title="源码下载"></a><font color="#2C3E50">源码下载</font></h2><p>这个比较简单,直接到solr的官网上下载源码即可,这里以<a href="https://www.apache.org/dyn/closer.lua/lucene/solr/7.7.2/solr-7.7.2-src.tgz" target="_blank" rel="noopener">Solr 7.7.2</a>为例子。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl <span class="string">"https://www.apache.org/dyn/closer.lua/lucene/solr/7.7.2/solr-7.7.2-src.tgz"</span> -o solr-7.7.2-src.tgz &amp;&amp; tar -xvf solr-7.7.2-src.tgz</span><br></pre></td></tr></table></figure></p><h2 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a><font color="#2C3E50">安装依赖</font></h2><blockquote><ul><li>jdk 1.8 </li><li>ant</li></ul></blockquote><p>笔者使用的是RedHat 系统，所以jdk的安装直接使用yum就行<br><a id="more"></a><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install  java-1.8.0-openjdk-devel.x86_64</span><br></pre></td></tr></table></figure></p><p>ant需要配置一下环境，也不算复杂<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl <span class="string">"http://mirrors.tuna.tsinghua.edu.cn/apache//ant/binaries/apache-ant-1.9.14-bin.tar.gz"</span> -o apache-ant-1.9.14-bin.tar.gz</span><br><span class="line">tar -xvf apache-ant-1.9.14-bin.tar.gz</span><br><span class="line">rm -rf apache-ant-1.9.14-bin.tar.gz</span><br></pre></td></tr></table></figure></p><p>配置环境变量(以RedHat为例),追加以下信息到~/.bash_profile (~/.bash_profile)，这里我把ant安装到了/opt目录下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> ANT_HOME=/opt/apache-ant-1.9.14</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$ANT_HOME</span>/bin</span><br></pre></td></tr></table></figure></p><p>简单验证下，看到以下结果就算ok了(source ~/.bash_profile 是为了使刚刚的配置生效)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$source</span> ~/.bash_profile</span><br><span class="line"><span class="variable">$ant</span> -version</span><br><span class="line">Apache Ant(TM) version 1.9.14 compiled on March 12 2019</span><br></pre></td></tr></table></figure></p><h2 id="Build源码"><a href="#Build源码" class="headerlink" title="Build源码"></a><font color="#2C3E50">Build源码</font></h2><p>Solr的源码是使用ivy来管理依赖的，所以需要安装ivy的lib包，但是Solr的项目中可以通过<strong>ant ivy-bootstrap</strong>直接下载ivy的jar包,这里看到”BUILD SUCCESSFUL”表示执行成功了。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$cd</span> solr-7.7.2</span><br><span class="line"><span class="variable">$ant</span> ivy-bootstrap</span><br><span class="line">-ivy-bootstrap1:</span><br><span class="line">    [mkdir] Created dir: /home/fql/.ant/lib</span><br><span class="line">     [<span class="built_in">echo</span>] installing ivy 2.4.0 to /home/fql/.ant/lib</span><br><span class="line">      [get] Getting: https://repo1.maven.org/maven2/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar</span><br><span class="line">      [get] To: /home/fql/.ant/lib/ivy-2.4.0.jar</span><br><span class="line">-ivy-bootstrap2:</span><br><span class="line">-ivy-checksum:</span><br><span class="line">-ivy-remove-old-versions:</span><br><span class="line">ivy-bootstrap:</span><br><span class="line">BUILD SUCCESSFUL</span><br></pre></td></tr></table></figure></p><h2 id="生成Intelij-Idea-Eclipse项目"><a href="#生成Intelij-Idea-Eclipse项目" class="headerlink" title="生成Intelij Idea/Eclipse项目"></a><font color="#2C3E50">生成Intelij Idea/Eclipse项目</font></h2><p>Intelij Idea 是笔者从2013年开始用的，之前用的都是Eclipse,这里不比较两个工具的好坏，能完成项目开发就行，这里以导入Intellij Idea 为例子 (如果是eclipse则为<strong>ant eclipse</strong>)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$cd</span> solr-7.7.2</span><br><span class="line"><span class="variable">$ant</span> idea</span><br></pre></td></tr></table></figure></p><p>这个执行的过程比较长，是因为ivy会从maven的官方repo下载依赖,这里可以去喝杯茶等着程序自动执行完成就行.</p><h4 id="如何解决下载不了org-restlet打头的包"><a href="#如何解决下载不了org-restlet打头的包" class="headerlink" title="如何解决下载不了org.restlet打头的包"></a><font color="#2C3E50">如何解决下载不了org.restlet打头的包</font></h4><p>可能你在执行ant test的时候会遇到类似以下的错误<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">resolve:</span><br><span class="line">[ivy:retrieve] </span><br><span class="line">[ivy:retrieve] :: problems summary ::</span><br><span class="line">[ivy:retrieve] :::: WARNINGS</span><br><span class="line">[ivy:retrieve] [FAILED     ] org.restlet.jee#org.restlet;2.3.0!org.restlet.jar:  (0ms)</span><br><span class="line">[ivy:retrieve] ==== shared: tried</span><br><span class="line">[ivy:retrieve]   /home/fql/.ivy2/shared/org.restlet.jee/org.restlet/2.3.0/jars/org.restlet.jar</span><br><span class="line">[ivy:retrieve] ==== public: tried</span><br><span class="line">[ivy:retrieve]   https://repo1.maven.org/maven2/org/restlet/jee/org.restlet/2.3.0/org.restlet-2.3.0.jar</span><br><span class="line">[ivy:retrieve] [FAILED     ] org.restlet.jee#org.restlet.ext.servlet;2.3.0!org.restlet.ext.servlet.jar:  (0ms)</span><br><span class="line">[ivy:retrieve] ==== shared: tried</span><br><span class="line">[ivy:retrieve]   /home/fql/.ivy2/shared/org.restlet.jee/org.restlet.ext.servlet/2.3.0/jars/org.restlet.ext.servlet.jar</span><br><span class="line">[ivy:retrieve] ==== public: tried</span><br><span class="line">[ivy:retrieve]   https://repo1.maven.org/maven2/org/restlet/jee/org.restlet.ext.servlet/2.3.0/org.restlet.ext.servlet-2.3.0.jar</span><br><span class="line">[ivy:retrieve] ::::::::::::::::::::::::::::::::::::::::::::::</span><br><span class="line">[ivy:retrieve] ::              FAILED DOWNLOADS            ::</span><br><span class="line">[ivy:retrieve] :: ^ see resolution messages for details  ^ ::</span><br><span class="line">[ivy:retrieve] ::::::::::::::::::::::::::::::::::::::::::::::</span><br><span class="line">[ivy:retrieve] :: org.restlet.jee#org.restlet;2.3.0!org.restlet.jar</span><br><span class="line">[ivy:retrieve] :: org.restlet.jee#org.restlet.ext.servlet;2.3.0!org.restlet.ext.servlet.jar</span><br><span class="line">[ivy:retrieve] ::::::::::::::::::::::::::::::::::::::::::::::</span><br><span class="line">[ivy:retrieve] </span><br><span class="line">[ivy:retrieve] :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS</span><br><span class="line"></span><br><span class="line">BUILD FAILED</span><br><span class="line">/home/fql/IdeaProjects/solr-7.7.2/build.xml:140: The following error occurred while executing this line:</span><br><span class="line">/home/fql/IdeaProjects/solr-7.7.2/solr/build.xml:602: The following error occurred while executing this line:</span><br><span class="line">/home/fql/IdeaProjects/solr-7.7.2/solr/core/build.xml:68: impossible to resolve dependencies:</span><br><span class="line">resolve failed - see output for details</span><br></pre></td></tr></table></figure></p><p>这是因为这个依赖的目录已经在~/.ivy2/cache下面的目录生成了，但是jar下载失败导致的，直接删除对应的目录重新执行<strong>ant test</strong> 就行了,以上面的错误为例，具体执行的命令为<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -rf ~/.ivy2/cache/org.restlet*</span><br><span class="line">ant <span class="built_in">test</span></span><br></pre></td></tr></table></figure></p><h2 id="导入Idea"><a href="#导入Idea" class="headerlink" title="导入Idea"></a><font color="#2C3E50">导入Idea</font></h2><p>执行完<strong>ant idea</strong>之后，如果看见以下类似输出表示build成功，我们可以开始将项目导入<strong>Intelij Idea</strong>了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">-post-idea-instructions:</span><br><span class="line">     [echo] </span><br><span class="line">     [echo] To complete IntelliJ IDEA setup, you must manually configure</span><br><span class="line">     [echo] File | Project Structure | Project | Project SDK.</span><br><span class="line">     [echo]       </span><br><span class="line">     [echo] You won&apos;t have to do this in the future if you define property</span><br><span class="line">     [echo] $&#123;idea.jdk&#125;, e.g. in ~/lucene.build.properties, ~/build.properties</span><br><span class="line">     [echo] or lucene/build.properties, with a value consisting of the</span><br><span class="line">     [echo] following two XML attributes/values (adjust values according to</span><br><span class="line">     [echo] JDKs you have defined locally - see </span><br><span class="line">     [echo] File | Project Structure | Platform Settings | SDKs):</span><br><span class="line">     [echo] </span><br><span class="line">     [echo]     idea.jdk = project-jdk-name=&quot;1.8&quot; project-jdk-type=&quot;JavaSDK&quot;</span><br><span class="line">     [echo]     </span><br><span class="line"></span><br><span class="line">BUILD SUCCESSFUL</span><br></pre></td></tr></table></figure></p><p>打开Intelij Idea , 选择文件-&gt;打开-&gt;选择源码的路径打开即可,Eclipse 直接选择从本地文件系统中打开项目即可。<br><img src="https://s2.ax1x.com/2019/10/01/uUfCDg.png" alt="项目导入"><br>至此，我们已经完成将项目导入到Intelij Idea，下面我会分享如何在Intelij Idea中debug Solr 的源码。</p><h2 id="参考的网址"><a href="#参考的网址" class="headerlink" title="参考的网址"></a><font color="#2C3E50">参考的网址</font></h2><blockquote><ul><li><a href="https://stackoverflow.com/questions/30630227/java-ivy-maven-build-dependency-resolution-for-lucidworks-auto-phrase-tokenizer" target="_blank" rel="noopener">https://stackoverflow.com/questions/30630227/java-ivy-maven-build-dependency-resolution-for-lucidworks-auto-phrase-tokenizer</a></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;玩转Solr源码之—Solr源码导入IDE&quot;&gt;&lt;a href=&quot;#玩转Solr源码之—Solr源码导入IDE&quot; class=&quot;headerlink&quot; title=&quot;玩转Solr源码之—Solr源码导入IDE&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#0077bb&quot;&gt;玩转Solr源码之—Solr源码导入IDE&lt;/font&gt;&lt;/h1&gt;&lt;h2 id=&quot;源码下载&quot;&gt;&lt;a href=&quot;#源码下载&quot; class=&quot;headerlink&quot; title=&quot;源码下载&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#2C3E50&quot;&gt;源码下载&lt;/font&gt;&lt;/h2&gt;&lt;p&gt;这个比较简单,直接到solr的官网上下载源码即可,这里以&lt;a href=&quot;https://www.apache.org/dyn/closer.lua/lucene/solr/7.7.2/solr-7.7.2-src.tgz&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Solr 7.7.2&lt;/a&gt;为例子。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;curl &lt;span class=&quot;string&quot;&gt;&quot;https://www.apache.org/dyn/closer.lua/lucene/solr/7.7.2/solr-7.7.2-src.tgz&quot;&lt;/span&gt; -o solr-7.7.2-src.tgz &amp;amp;&amp;amp; tar -xvf solr-7.7.2-src.tgz&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装依赖&quot;&gt;&lt;a href=&quot;#安装依赖&quot; class=&quot;headerlink&quot; title=&quot;安装依赖&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#2C3E50&quot;&gt;安装依赖&lt;/font&gt;&lt;/h2&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;jdk 1.8 &lt;/li&gt;
&lt;li&gt;ant&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;笔者使用的是RedHat 系统，所以jdk的安装直接使用yum就行&lt;br&gt;
    
    </summary>
    
    
      <category term="Solr" scheme="https://www.fengqinglei.top/tags/Solr/"/>
    
      <category term="源码" scheme="https://www.fengqinglei.top/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="Intelij Idea" scheme="https://www.fengqinglei.top/tags/Intelij-Idea/"/>
    
      <category term="Eclipse" scheme="https://www.fengqinglei.top/tags/Eclipse/"/>
    
      <category term="ant" scheme="https://www.fengqinglei.top/tags/ant/"/>
    
  </entry>
  
  <entry>
    <title>IBM ICU 简繁转换工具的性能坑</title>
    <link href="https://www.fengqinglei.top/2019/07/21/IBMICUSlowIssue/"/>
    <id>https://www.fengqinglei.top/2019/07/21/IBMICUSlowIssue/</id>
    <published>2019-07-21T06:33:05.000Z</published>
    <updated>2019-09-27T00:46:01.319Z</updated>
    
    <content type="html"><![CDATA[<h1 id="IBM-ICU-简繁转换工具的性能坑"><a href="#IBM-ICU-简繁转换工具的性能坑" class="headerlink" title="IBM ICU 简繁转换工具的性能坑"></a><font color="#0077bb">IBM ICU 简繁转换工具的性能坑</font></h1><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a><font color="#2C3E50">背景介绍</font></h2><p>由于工作内容的需要，我们处理的文本数据中会有繁体中文，但是我们的产品的使用客户都是习惯使用简体中文（台湾是中国不可割舍的一部分），所以为了方便用户使用简体中文检索到繁体中文，我们需要在建立索引的时候（这里以solr为例子）进行简繁转换。简单的查看了Solr的文档，以及简单的百度或者Google, 我们可以在Solr(7.7.2)中添加以下的字段类型来进行中文分词和简繁转换。<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">fieldType</span> <span class="attr">name</span>=<span class="string">"test"</span>  <span class="attr">class</span>=<span class="string">"solr.TextField"</span> &gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">analyzer</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">charFilter</span> <span class="attr">class</span>=<span class="string">"solr.HTMLStripCharFilterFactory"</span>/&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">charFilter</span> <span class="attr">class</span>=<span class="string">"solr.MappingCharFilterFactory"</span> <span class="attr">mapping</span>=<span class="string">"mapping-ISOLatin1Accent.txt"</span>/&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">tokenizer</span> <span class="attr">class</span>=<span class="string">"solr.StandardTokenizerFactory"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"solr.CJKWidthFilterFactory"</span>/&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"solr.ICUTransformFilterFactory"</span> <span class="attr">id</span>=<span class="string">"Traditional-Simplified"</span>/&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"solr.LowerCaseFilterFactory"</span>/&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"solr.CJKBigramFilterFactory"</span> <span class="attr">han</span>=<span class="string">"true"</span> <span class="attr">outputUnigrams</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">analyzer</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">fieldType</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>可以看到这是最简单的中文分词器-&gt; 二元分词，并且在二元的基础上输出了一元的结果，这里可以简单看下分词结果<br><img src="https://s2.ax1x.com/2019/07/21/eCmvwt.png" alt="二元+一元分词效果"><br>似乎配置+使用起来也就5s(666),但是实际情况是性能不够，射不高，跑不快。<br><a id="more"></a></p><h2 id="发现问题"><a href="#发现问题" class="headerlink" title="发现问题"></a><font color="#2C3E50">发现问题</font></h2><p>因为是需要上线的服务，所以习惯性的需要在本地进行一些索引和查询的性能测试，为了测试索引的性能，我准备了2700万的文档数据（包含简体中文和繁体中文），进行压缩之后这些文档大小在135GB左右，基本上可以做一个长时间的性能摸底测试了。<br>我们简单的看下用户测试的机器配置</p><div class="table-container"><table><thead><tr><th style="text-align:center">机器类型</th><th style="text-align:center">CPU 配置</th><th style="text-align:center">内存配置</th><th style="text-align:center">磁盘配置</th></tr></thead><tbody><tr><td style="text-align:center">Solr服务机器</td><td style="text-align:center">12 Core Intel(R) Xeon(R) CPU E5-2420 v2 @ 2.20GHz</td><td style="text-align:center">30GB</td><td style="text-align:center">7TB LVM</td></tr><tr><td style="text-align:center">索引机器</td><td style="text-align:center">4 Core Intel(R) Core(TM) i5-4590 CPU @ 3.30GHz</td><td style="text-align:center">16GB</td><td style="text-align:center">1TB HDD</td></tr></tbody></table></div><p>并且<strong>索引机器</strong> 和 <strong>Solr 服务机器</strong> 之前的网络为千兆带宽，所以网络上不会成为瓶颈。<br>并且Solr 的一些重要配置为</p><blockquote><ul><li>内存配置为SOLR_JAVA_MEM=”-Xms6144m -Xmx6144m”</li><li><p>ramBufferSizeMB配置为</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ramBufferSizeMB</span>&gt;</span>100<span class="tag">&lt;/<span class="name">ramBufferSizeMB</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>mergePolicyFactory 为</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">mergePolicyFactory</span> <span class="attr">class</span>=<span class="string">"org.apache.solr.index.TieredMergePolicyFactory"</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">int</span> <span class="attr">name</span>=<span class="string">"maxMergeAtOnce"</span>&gt;</span>30<span class="tag">&lt;/<span class="name">int</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">int</span> <span class="attr">name</span>=<span class="string">"segmentsPerTier"</span>&gt;</span>40<span class="tag">&lt;/<span class="name">int</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">double</span> <span class="attr">name</span>=<span class="string">"noCFSRatio"</span>&gt;</span>0<span class="tag">&lt;/<span class="name">double</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">int</span> <span class="attr">name</span>=<span class="string">"maxMergedSegmentMB"</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">int</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mergePolicyFactory</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>mergeScheduler 为</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">mergeScheduler</span> <span class="attr">class</span>=<span class="string">"org.apache.lucene.index.ConcurrentMergeScheduler"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">int</span> <span class="attr">name</span>=<span class="string">"maxMergeCount"</span>&gt;</span>12<span class="tag">&lt;/<span class="name">int</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">int</span> <span class="attr">name</span>=<span class="string">"maxThreadCount"</span>&gt;</span>6<span class="tag">&lt;/<span class="name">int</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mergeScheduler</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>autoCommit 的配置为 (防止频繁的autocommit生成太多的小段导致Solr一直在合并段)</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">autoCommit</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">maxTime</span>&gt;</span>$&#123;solr.autoCommit.maxTime:180000&#125;<span class="tag">&lt;/<span class="name">maxTime</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">openSearcher</span>&gt;</span>false<span class="tag">&lt;/<span class="name">openSearcher</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">autoCommit</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul></blockquote><p>为了仅可能的用尽服务端的CPU，我在客户端开了20个线程往服务端丢数据，理论上应该可以将服务端的cpu跑满。但是实际的服务端cpu使用情况为<img src="https://s2.ax1x.com/2019/07/21/eCCX59.png" alt="Solr Server CPU usage"><br>并且客户端的索引速度只有<strong>404 doc/s</strong> (因为和具体的文档的大小和内容有关系，速度的值并没有太多的参考意义，我们需要观察的更多的速度的变化率)<br>显然这个结果（cpu使用率）和预期的相差非常大？为啥还有那么多的cpu资源在idl ？？</p><h2 id="定位问题"><a href="#定位问题" class="headerlink" title="定位问题"></a><font color="#2C3E50">定位问题</font></h2><p>为了搞清楚为啥会有这么多cpu在idl，最简单的办法就是使用一些jvm的profile工具，可以看到cpu把大量的资源消耗在什么地方，从而我们可以定位到发生问题的代码的类甚至某一行，这里我们使用的工具是<a href="https://visualvm.github.io/" target="_blank" rel="noopener">VisualVM</a>,当然为了能够让VisualVM能够访问服务端的jvm进程，我们需要对Solr进行一些配置，这个比较简单，主要是修改<strong>solr.in.sh</strong>文件的内容，直接上具体的配置点<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SOLR_OPTS=<span class="string">"<span class="variable">$SOLR_OPTS</span> -Dcom.sun.management.jmxremote"</span></span><br><span class="line">SOLR_OPTS=<span class="string">"<span class="variable">$SOLR_OPTS</span> -Dcom.sun.management.jmxremote.port=28983"</span></span><br><span class="line">SOLR_OPTS=<span class="string">"<span class="variable">$SOLR_OPTS</span> -Dcom.sun.management.jmxremote.ssl=false"</span></span><br><span class="line">SOLR_OPTS=<span class="string">"<span class="variable">$SOLR_OPTS</span> -Dcom.sun.management.jmxremote.authenticate=false"</span></span><br><span class="line">SOLR_OPTS=<span class="string">"<span class="variable">$SOLR_OPTS</span> -Djava.rmi.server.hostname=192.168.18.2"</span></span><br></pre></td></tr></table></figure></p><p>重新开启服务端和客户端进行压力测试（之前的数据已经清理掉了），在程序运行了几分钟之后我们可以通过VisualVM的CPU profile功能发现，大量的cpu时间被消耗在了<strong>com.ibm.icu.text.RuleBasedTransliterator.handlerTransliterate()</strong> 方法上了,<br><img src="https://s2.ax1x.com/2019/07/21/eCeRVP.png" alt="VisualVM CPU Profile"><br>回想了下Solr的中的字段的定了中有个<strong>solr.ICUTransformFilterFactory</strong>filter，显然就是这个filter耗费了大量的cpu时间（看包名和类型就能联想到）,为了简单的验证是不是这个类导致的问题，我简单的做了下对比实验，我可以把这个filter注释掉看下服务端的cpu使用率和客户端的索引速度。直接修改schema中的field type定义<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">fieldType</span> <span class="attr">name</span>=<span class="string">"test"</span>  <span class="attr">class</span>=<span class="string">"solr.TextField"</span> &gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">analyzer</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">charFilter</span> <span class="attr">class</span>=<span class="string">"solr.HTMLStripCharFilterFactory"</span>/&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">charFilter</span> <span class="attr">class</span>=<span class="string">"solr.MappingCharFilterFactory"</span> <span class="attr">mapping</span>=<span class="string">"mapping-ISOLatin1Accent.txt"</span>/&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">tokenizer</span> <span class="attr">class</span>=<span class="string">"solr.StandardTokenizerFactory"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"solr.CJKWidthFilterFactory"</span>/&gt;</span></span><br><span class="line">                <span class="comment">&lt;!-- &lt;filter class="solr.ICUTransformFilterFactory" id="Traditional-Simplified"/&gt; --&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"solr.LowerCaseFilterFactory"</span>/&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"solr.CJKBigramFilterFactory"</span> <span class="attr">han</span>=<span class="string">"true"</span> <span class="attr">outputUnigrams</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">analyzer</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">fieldType</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>然后重新开启服务端和客户端进行压力测试（之前的数据已经清理掉了），直接上cpu使用率和索引速度信息<br><img src="https://s2.ax1x.com/2019/07/21/eCAuWj.png" alt="Solr Server CPU usage"><br>并且客户端的索引速度也飙到了<strong>900 doc/s</strong>，尼玛坑爹的<strong>ICUTransformFilterFactory</strong>,搞个简繁转换还能搞出个幺蛾子，再看下VisualVM  的cpu profile结果<br><img src="https://s2.ax1x.com/2019/07/21/eCenH0.png" alt="VisualVM CPU Profile"><br>症状100%消失,更加肯定就是<strong>ICUTransformFilterFactory</strong>搞出来的幺蛾子，怎么弄个简繁转换还能出这种问题，弱爆了。。。</p><h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a><font color="#2C3E50">源码分析</font></h2><p>为了100%确认真的是<strong>ICUTransformFilterFactory</strong>导致的问题，我下载了Solr-7.7.2的源代码，并且进行了源码的debug，<br>最终在<strong>com.ibm.icu.text.RuleBasedTransliterator.handlerTransliterate()</strong>中找到的真正的问题所在，废话不说上代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Deprecated</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">handleTransliterate</span><span class="params">(Replaceable text, Position index, <span class="keyword">boolean</span> incremental)</span> </span>&#123;</span><br><span class="line">        RuleBasedTransliterator.Data var4 = <span class="keyword">this</span>.data;</span><br><span class="line">        <span class="keyword">synchronized</span>(<span class="keyword">this</span>.data) &#123;</span><br><span class="line">            <span class="keyword">int</span> loopCount = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">int</span> loopLimit = index.limit - index.start &lt;&lt; <span class="number">4</span>;</span><br><span class="line">            <span class="keyword">if</span>(loopLimit &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                loopLimit = <span class="number">2147483647</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span>(index.start &lt; index.limit &amp;&amp; loopCount &lt;= loopLimit &amp;&amp; <span class="keyword">this</span>.data.ruleSet.transliterate(text, index, incremental)) &#123;</span><br><span class="line">                ++loopCount;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>可见看见大大的<strong>synchronized</strong>关键字，难怪嘛，Solr的索引是多线程的，并且在看了ICU的一些初始化过程之后，在简繁转换这个case上的RuleBasedTransliterator.Data只用初始化一次就好，（具体的过程比较复杂，简单的来说这中简繁转换的rule来自于配置文件，显然配置文件不可能加载多次），所以一旦上了多线程就各种卡，cpu全消耗在内斗上了，哎。。。。，不过好消息是这个<strong>RuleBasedTransliterator</strong>类已经被打上了<strong>Deprecated</strong>标签了，所以估计在高版本的icu api中这个问题会不复存在。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a><font color="#2C3E50">解决方案</font></h2><p>最简单的解决方案就是等—&gt; 等官方干掉这个类，这样期待在未来的版本中icu不再使用这个坑爹的<strong>synchronized</strong>关键字，当然这显然不是最好的版本，当然还有一种相对简单的方案就是直接干掉<strong>synchronized</strong>关键字，然后重新编译打包一下就好，如果只是为了写这篇博客确实可以这么干，因为后期的维护成本为0，但是在真是的企业开发中还是不太可取的，如果solr今后版本升级，我们也要下载对应的icu包然后去掉<strong>synchronized</strong>关键字，然后在重新编译打包等操作，虽然说是一次性工作，但是相当于我们间接的在维护icu的源码了。<br>还有一种最暴力的做法，但是却是我比较推荐的做法，我们可以自己造一个简繁转换的solrplugin，确实，只是简单的简体中文到繁体中文的转换，我们只需要找到简繁的对照表就可以做了。说干就干，我直接提取了icu包中的简体中文和繁体中文的对照表（当然获取途径有多种，甚至wiki上都有），这里是我提取的<a href="https://github.com/fengqingleiyue/apache-solr-plugins/blob/master/zh-converter/src/main/resources/hant_hans.properties" target="_blank" rel="noopener">简体繁体对照表</a>,有了简繁转换表，那么solrplugin也就相对简单了，不多说，直接上<a href="https://github.com/fengqingleiyue/apache-solr-plugins/tree/master/zh-converter" target="_blank" rel="noopener">代码</a>,为了验证问题是否解决，我简单做了下对比测试，索引速度直接从原来的<strong>401/s</strong>上升到了<strong>936/s</strong> ,服务端的cpu使用率也能够飙升至<strong>90%</strong>左右，直接上图<img src="https://s2.ax1x.com/2019/08/18/mlPsMT.png" alt="Solr Server CPU Usage">至此icu导致的性能问题，已经得到解决。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;IBM-ICU-简繁转换工具的性能坑&quot;&gt;&lt;a href=&quot;#IBM-ICU-简繁转换工具的性能坑&quot; class=&quot;headerlink&quot; title=&quot;IBM ICU 简繁转换工具的性能坑&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#0077bb&quot;&gt;IBM ICU 简繁转换工具的性能坑&lt;/font&gt;&lt;/h1&gt;&lt;h2 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#2C3E50&quot;&gt;背景介绍&lt;/font&gt;&lt;/h2&gt;&lt;p&gt;由于工作内容的需要，我们处理的文本数据中会有繁体中文，但是我们的产品的使用客户都是习惯使用简体中文（台湾是中国不可割舍的一部分），所以为了方便用户使用简体中文检索到繁体中文，我们需要在建立索引的时候（这里以solr为例子）进行简繁转换。简单的查看了Solr的文档，以及简单的百度或者Google, 我们可以在Solr(7.7.2)中添加以下的字段类型来进行中文分词和简繁转换。&lt;br&gt;&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;fieldType&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;test&quot;&lt;/span&gt;  &lt;span class=&quot;attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;solr.TextField&quot;&lt;/span&gt; &amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;         &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;analyzer&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;charFilter&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;solr.HTMLStripCharFilterFactory&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;charFilter&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;solr.MappingCharFilterFactory&quot;&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;mapping&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;mapping-ISOLatin1Accent.txt&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;solr.StandardTokenizerFactory&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;solr.CJKWidthFilterFactory&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;solr.ICUTransformFilterFactory&quot;&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;id&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;Traditional-Simplified&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;solr.LowerCaseFilterFactory&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;solr.CJKBigramFilterFactory&quot;&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;han&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;true&quot;&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;outputUnigrams&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;true&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;         &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;analyzer&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;fieldType&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;可以看到这是最简单的中文分词器-&amp;gt; 二元分词，并且在二元的基础上输出了一元的结果，这里可以简单看下分词结果&lt;br&gt;&lt;img src=&quot;https://s2.ax1x.com/2019/07/21/eCmvwt.png&quot; alt=&quot;二元+一元分词效果&quot;&gt;&lt;br&gt;似乎配置+使用起来也就5s(666),但是实际情况是性能不够，射不高，跑不快。&lt;br&gt;
    
    </summary>
    
    
      <category term="Solr" scheme="https://www.fengqinglei.top/tags/Solr/"/>
    
      <category term="IBM ICU" scheme="https://www.fengqinglei.top/tags/IBM-ICU/"/>
    
      <category term="Traditional-Simplified" scheme="https://www.fengqinglei.top/tags/Traditional-Simplified/"/>
    
      <category term="Performance" scheme="https://www.fengqinglei.top/tags/Performance/"/>
    
      <category term="性能调优" scheme="https://www.fengqinglei.top/tags/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"/>
    
  </entry>
  
  <entry>
    <title>如何动态设置Solr Payload</title>
    <link href="https://www.fengqinglei.top/2019/07/10/SolrPayLoads/"/>
    <id>https://www.fengqinglei.top/2019/07/10/SolrPayLoads/</id>
    <published>2019-07-10T15:05:22.000Z</published>
    <updated>2019-09-27T00:41:27.954Z</updated>
    
    <content type="html"><![CDATA[<h1 id="如何动态设置Solr-Payload"><a href="#如何动态设置Solr-Payload" class="headerlink" title="如何动态设置Solr Payload "></a><font color="#0077bb">如何动态设置Solr Payload </font></h1><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a><font color="#2C3E50">问题背景</font></h2><p>Solr 从6.x开始提供了index payload的功能，（payload是指可以指定为分词之后的每个term指定一个二进制的信息，用于针对每个term作出一定的行为，例如可以用来存储指定的score用于排序，也可以用来存储指定的数据，用于检查term的一定的检查），简单的查阅官方文档之后（这里使用solr7.7.2作为样例）,得知我们可以动态的设定每个term的payload（参考<a href="https://lucidworks.com/post/end-to-end-payload-example-in-solr/" target="_blank" rel="noopener">SolrPayload</a>），也可以根据指定的token type设置payload数值(参考<a href="https://lucene.apache.org/solr/guide/7_4/filter-descriptions.html#numeric-payload-token-filter" target="_blank" rel="noopener">Numeric Payload Token Filter</a>)，但是上述两种方式都无法根据输入的变化而动态的改变payload的值。<br><a id="more"></a></p><h3 id="具体需求"><a href="#具体需求" class="headerlink" title="具体需求"></a><font color="#2C3E50">具体需求</font></h3><p>由于和具体的的业务有关，我这里将需求简单化。</p><blockquote><ul><li>业务中的字段类型为多值字段</li><li>同一篇文档的多值字段中不同的数值需要设置不同的payload</li><li>需要更具不同的参数设定不同的payload数值</li></ul></blockquote><p>看到这里老司机肯定说这个需求太简单了，直接使用<strong>Numeric Payload Token Filter</strong> 就行了，可以将多值字段放到多个字段中，每个字段指定不同的payload的问题也可以解决啊 (只需要指定不同字段类型下面例子中的payload值就行了)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;analyzer&gt;</span><br><span class="line">  &lt;tokenizer class=&quot;solr.WhitespaceTokenizerFactory&quot;/&gt;</span><br><span class="line">  &lt;filter class=&quot;solr.NumericPayloadTokenFilterFactory&quot; payload=&quot;0.75&quot; typeMatch=&quot;word&quot;/&gt;</span><br><span class="line">&lt;/analyzer&gt;</span><br></pre></td></tr></table></figure></p><p>确实，在多值字段的值的个数较少的时候我也推荐这种做法，因为相对比较简单，而且容易操作。但是如果我有多值字段有20个值，那么这样我的schema里面必须得有20个字段类型，20个字段来对应的多个payload ,那么管理这20个字段就变成了一件蛋疼的事情。<br>当然这里也有人会说为啥不用solr的<strong>DelimitedPayloadTokenFilter</strong>(<a href="https://lucidworks.com/post/solr-payloads/）" target="_blank" rel="noopener">用法可以参考</a>,我们可以手动指定每个term的payload，例如 (分隔符|后面的数字为payload)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">id,vals_dpf</span><br><span class="line">1,one|1.0 two|2.0 three|3.0</span><br><span class="line">2,weighted|50.0 weighted|100.0</span><br></pre></td></tr></table></figure></p><p>是的，确实可以，但是前提是你的文档内容比较简单（内容简单的话推荐使用<strong>DelimitedPayloadTokenFilter</strong>,可以在index代码中根据业务动态控制），如果文档比较复杂，比如就是一段文本，那么相当于你得在index代码中将文本进行分词然后拼接成上述的例子，但是如果拼接的话solr的分词功能就形同摆设了，那么有没有办法既能保持index代码的简单性，也可以使用solr的分词功能来完成上述的需求呢？</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a><font color="#2C3E50">解决方案</font></h2><p>解决方案其实只有两步</p><blockquote><ul><li>可以动态的设置某个字段的某个值的某个属性</li><li>自定Tokenizer或者filter根据某个属性设定对用的payload</li></ul></blockquote><p>(我去，这简直就是正确的废话)<br>那么既然我们的“解决方案”已经有了，我们该怎么一步步的实现这个“解决方案呢”，我们来一步步分析下，</p><blockquote><ul><li>我们怎么动态的设置某个字段的某个值的某个属性？</li></ul></blockquote><p>由于在index的代码中，Solr的给我们的API比较简单，直接就是 SolrInputDocument.set(fieldname,fieldvalue),我们能控制的要么就是fieldname，要么就是fieldvalue， 控制fieldname的方案我前面已经介绍过,可以使用<strong>Numeric Payload Token Filter</strong> 来解决我们的问题，这里我们可能设法在fieldname上做文章了，那么可以选择的方案只能是在fieldvalue上下功夫了，显然，我们只能在fieldvalue的头上加一些特殊的标记来解决问题，当然这些特殊的标记不能和你的字段值的某个或者某些特征发生冲突，例如我们可以在字段值的前段加上”[|xxx|]”,那么我们就可以在更具xxx的内容设定某个字段的某个属性就行了</p><blockquote><ul><li>如何在solr端读取xxx的内容？</li></ul></blockquote><p>solr的index功能是基于Lucene提供的，那么Lucene给我的api也比较简单<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Document doc = new Document();</span><br><span class="line">doc.add(new StringField(&quot;fieldName&quot;,&quot;document context&quot;, Field.Store.YES));</span><br></pre></td></tr></table></figure></p><p>也就是所有的文档的字段到lucene这一层肯定都是转成一个document，然后向文档里面添加对应的字段，不同的字段使用不同的分词器来进行分词，对，我们可以自定义字段，在生成这个字段的时候解析<strong>xxx</strong>的内容，并且根据<strong>xxx</strong>的内容设定某个属性的值问题不就能解决了吗？<br>简单的翻看了Solr的某个字段类型的源码（这里以<strong>Solr.TextField</strong>为例子）<br><img src="https://s2.ax1x.com/2019/07/21/epDlO1.png" alt="Solr.TextField Method List"> ,都是一些get方法，貌似没啥用，看看父类<strong>org.apache.solr.schema.FieldType</strong><br><img src="https://s2.ax1x.com/2019/07/21/epDVoT.png" alt="FieldType Method List"><br>貌似<strong>createField</strong>就是我们要找的方法，我们可以在这里解析fieldvalue ,并且根据<strong>xxx</strong>设置这个字段的某个属性，然后拿掉<strong>xxx</strong>,还原原始的fieldvalue</p><blockquote><ul><li>“某个属性”到底是哪个属性</li></ul></blockquote><p>在上文中我们一直提到“某个属性”，但是我们到目前为止还是没有找到这个可以设置的属性到底是啥，但是如果我们不找到这个属性，上面的分析过程全是扯淡的，为了找到这个属性，我们必须知道这个属性满足什么样的特征呢，我们分析下这个属性需要满足的特征</p><blockquote><blockquote><ul><li>这个属性不能对原始的fieldvalue产生变更</li></ul></blockquote></blockquote><p>为什么？按照我们的想法，这个”某个属性“不能对原始的fieldvalue参数影响，如果改变了原始value，</p><blockquote><blockquote><ul><li>这个属性可以必须是跟着term走的，并且可以在tokenizer和filter中可以获取</li></ul></blockquote></blockquote><p>为什么？按照我们的做法，我们必须在某个tokenizer或者filter或者这个属性，才能设置payload的值，其他的地方没发接触到payload </p><p>明确了上述两个特征，我们找个filter／tokenizer的源代码看下 ,找个最简单的<strong>LowerCaseFilter</strong> 看看<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LowerCaseFilter</span> <span class="keyword">extends</span> <span class="title">TokenFilter</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Create a new LowerCaseFilter, that normalizes token text to lower case.</span></span><br><span class="line"><span class="comment">   * </span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> in TokenStream to filter</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">LowerCaseFilter</span><span class="params">(TokenStream in)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(in);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">incrementToken</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (input.incrementToken()) &#123;</span><br><span class="line">      CharacterUtils.toLowerCase(termAtt.buffer(), <span class="number">0</span>, termAtt.length());</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span></span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>看到这里我们有了答案，原来CharTermAttribute就是Lucene／Solr原来在设定某个term的值的，那么我们可以自己造一个，放入根据<strong>xxx</strong>得到的属性，然后在filter里面或者这个属性，不就可以动态的设定payload的值了嘛， 对头， 上代码 </p><blockquote><ul><li>自定义Solr的Field </li></ul></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicPayloadsField</span> <span class="keyword">extends</span> <span class="title">TextField</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> IndexableField <span class="title">createField</span><span class="params">(SchemaField field, Object value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!field.indexed() &amp;&amp; !field.stored()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (log.isTraceEnabled())</span><br><span class="line">                log.trace(<span class="string">"Ignoring unindexed/unstored field: "</span> + field);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        String val;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            val = toInternal(value.toString());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (RuntimeException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> SolrException( SolrException.ErrorCode.SERVER_ERROR, <span class="string">"Error while creating field '"</span> + field + <span class="string">"' from value '"</span> + value + <span class="string">"'"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (val==<span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        String target = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (val.startsWith(<span class="string">"[|"</span>) &amp;&amp; val.contains(<span class="string">"|]"</span>)) &#123;</span><br><span class="line">            target = val.substring(<span class="number">2</span>,val.indexOf(<span class="string">"|]"</span>));</span><br><span class="line">            <span class="keyword">if</span> (DynamicPayloadAttribute.FIELD_MAPPINGS.containsKey(target)) &#123;</span><br><span class="line">                String parsedData = val.substring(val.indexOf(<span class="string">"|]"</span>)+<span class="number">2</span>);</span><br><span class="line">                TokenizerChain tokenizerChain = (TokenizerChain)field.getType().getIndexAnalyzer();</span><br><span class="line">                Tokenizer tk = tokenizerChain.getTokenizerFactory().create(TokenStream.DEFAULT_TOKEN_ATTRIBUTE_FACTORY);</span><br><span class="line">                TokenStream ts = tk;</span><br><span class="line">                <span class="keyword">for</span> (TokenFilterFactory filter : tokenizerChain.getTokenFilterFactories()) &#123;</span><br><span class="line">                    ts = filter.create(ts);</span><br><span class="line">                &#125;</span><br><span class="line">                Analyzer.TokenStreamComponents components = <span class="keyword">new</span> Analyzer.TokenStreamComponents(tk, ts);</span><br><span class="line">                Reader stringReader = tokenizerChain.initReader(field.getName(),<span class="keyword">new</span> StringReader(parsedData));</span><br><span class="line">                tk.setReader(stringReader);</span><br><span class="line">                TokenStream stream = components.getTokenStream();</span><br><span class="line">                stream.getAttribute(DynamicPayloadAttribute.class).setPayloadType(target);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Field(field.getName(), stream, field);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">super</span>.createField(field.getName(), val, field);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">super</span>.createField(field.getName(), val, field);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><ul><li>自定义Attribute</li></ul></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">DynamicPayloadAttribute</span> <span class="keyword">extends</span> <span class="title">Attribute</span> </span>&#123;</span><br><span class="line">    Map&lt;String,Integer&gt; FIELD_MAPPINGS = <span class="keyword">new</span> HashMap&lt;String,Integer&gt;()&#123;</span><br><span class="line">        &#123;</span><br><span class="line">            put(<span class="string">"A"</span>,<span class="number">0</span>);</span><br><span class="line">            put(<span class="string">"B"</span>,<span class="number">1</span>);</span><br><span class="line">            put(<span class="string">"C"</span>,<span class="number">2</span>);</span><br><span class="line">            put(<span class="string">"D"</span>,<span class="number">3</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    String DEFAULT_PAYLOAD_TYPE = <span class="string">"UNKNOW_PAYLOAD_TYPE"</span>;</span><br><span class="line">    <span class="function">String <span class="title">payloadType</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">setPayloadType</span><span class="params">(String type)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">byte</span> <span class="title">getPayLoad</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><ul><li>自定义filter</li></ul></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicPayloadTokenFilter</span> <span class="keyword">extends</span> <span class="title">TokenFilter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> PayloadAttribute payAtt = addAttribute(PayloadAttribute.class);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> DynamicPayloadAttribute dypayAtt = addAttribute(DynamicPayloadAttribute.class);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="title">DynamicPayloadTokenFilter</span><span class="params">(TokenStream input)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(input);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">incrementToken</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (input.incrementToken()) &#123;</span><br><span class="line">            <span class="keyword">byte</span> payload = dypayAtt.getPayLoad();</span><br><span class="line">            <span class="keyword">if</span>(payload==Byte.MAX_VALUE)&#123;</span><br><span class="line">                payAtt.setPayload(<span class="keyword">null</span>);</span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">byte</span> array [] = &#123;payload&#125;;</span><br><span class="line">                payAtt.setPayload(<span class="keyword">new</span> BytesRef(array));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我只放上了重要的代码片段，完整的代码请参考<a href="https://github.com/fengqingleiyue/apache-solr-plugins/tree/master/dynamic-payload" target="_blank" rel="noopener">apache-solr-plugins/dynamic-payload</a></p><h2 id="爬坑指南"><a href="#爬坑指南" class="headerlink" title="爬坑指南"></a><font color="#2C3E50">爬坑指南</font></h2><p>当然如果所有的细节都如上述描述那么简单，那么各位看官肯定觉得无聊死了，所有的程序员朋友们肯定更加关注这个过程中有没有什么坑，当然坑是存在的，坑是痛苦的，爬坑的过程是痛苦的，爬坑是需要分享的。<br>遇到的坑:<br>在Solr的<a href="http://127.0.0.1:8983/solr/#/TEST/documents" target="_blank" rel="noopener">document</a>页面上添加文档是成功的，但是一旦用代码上多线程立马报错（主要的错误就是TokenStream 在调用前没有调用reset方法）<br>在没有修正这个问题之前的<strong>createField</strong>的方法实现为（部分）<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (val.startsWith(<span class="string">"[|"</span>) &amp;&amp; val.contains(<span class="string">"|]"</span>)) &#123;</span><br><span class="line">           target = val.substring(<span class="number">2</span>,val.indexOf(<span class="string">"|]"</span>));</span><br><span class="line">           <span class="keyword">if</span> (DynamicPayloadAttribute.FIELD_MAPPINGS.containsKey(target)) &#123;</span><br><span class="line">               String parsedData = val.substring(val.indexOf(<span class="string">"|]"</span>)+<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">               TokenStream stream = field.getType().getIndexAnalyzer().tokenStream(field.getName(),parsedData);</span><br><span class="line">               stream.addAttributeImpl(<span class="keyword">new</span> DynamicPayloadAttributeImpl(target));</span><br><span class="line">               <span class="keyword">return</span> <span class="keyword">new</span> Field(field.getName(),stream,field);</span><br></pre></td></tr></table></figure></p><p>而问题就出现在tokenStream方法上<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">field.getType().getIndexAnalyzer().tokenStream(field.getName(),parsedData);</span><br></pre></td></tr></table></figure></p><p>进入实现可以看到TokenStreamComponents是会重用的<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> TokenStream <span class="title">tokenStream</span><span class="params">(String fieldName, String text)</span> </span>&#123;</span><br><span class="line">        Analyzer.TokenStreamComponents components = <span class="keyword">this</span>.reuseStrategy.getReusableComponents(<span class="keyword">this</span>, fieldName);</span><br><span class="line">        ReusableStringReader strReader = components != <span class="keyword">null</span> &amp;&amp; components.reusableStringReader != <span class="keyword">null</span>?components.reusableStringReader:<span class="keyword">new</span> ReusableStringReader();</span><br><span class="line">        strReader.setValue(text);</span><br><span class="line">        Reader r = <span class="keyword">this</span>.initReader(fieldName, strReader);</span><br><span class="line">        <span class="keyword">if</span>(components == <span class="keyword">null</span>) &#123;</span><br><span class="line">            components = <span class="keyword">this</span>.createComponents(fieldName);</span><br><span class="line">            <span class="keyword">this</span>.reuseStrategy.setReusableComponents(<span class="keyword">this</span>, fieldName, components);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        components.setReader(r);</span><br><span class="line">        components.reusableStringReader = strReader;</span><br><span class="line">        <span class="keyword">return</span> components.getTokenStream();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>这样做的好处就是不用重复生成tokenstream compents，并且不同的只是输入，其他的都是一样的，但是为啥在我们的应用场景就会报错呢，原来错误不再我们的使用方式上，而是在solr的后续的流程中会调用<strong>Field.tokenStream</strong>方法，并且在<strong>tokenStream</strong>属性不为空的情况下，就会直接return，所以想象下，如果同一个字段的不同值公用了同一个tokenstream属性，那么针对这个tokenstream设定的不同值，只会在最后一个调用的属性会成功。（显然这和我们的期望相违背）<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> TokenStream <span class="title">tokenStream</span><span class="params">(Analyzer analyzer, TokenStream reuse)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">this</span>.fieldType().indexOptions() == IndexOptions.NONE) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span>(!<span class="keyword">this</span>.fieldType().tokenized()) &#123;</span><br><span class="line">            <span class="keyword">if</span>(<span class="keyword">this</span>.stringValue() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span>(!(reuse <span class="keyword">instanceof</span> Field.StringTokenStream)) &#123;</span><br><span class="line">                    reuse = <span class="keyword">new</span> Field.StringTokenStream();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                ((Field.StringTokenStream)reuse).setValue(<span class="keyword">this</span>.stringValue());</span><br><span class="line">                <span class="keyword">return</span> (TokenStream)reuse;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span>(<span class="keyword">this</span>.binaryValue() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span>(!(reuse <span class="keyword">instanceof</span> Field.BinaryTokenStream)) &#123;</span><br><span class="line">                    reuse = <span class="keyword">new</span> Field.BinaryTokenStream();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                ((Field.BinaryTokenStream)reuse).setValue(<span class="keyword">this</span>.binaryValue());</span><br><span class="line">                <span class="keyword">return</span> (TokenStream)reuse;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Non-Tokenized Fields must have a String value"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span>(<span class="keyword">this</span>.tokenStream != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>.tokenStream;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span>(<span class="keyword">this</span>.readerValue() != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> analyzer.tokenStream(<span class="keyword">this</span>.name(), <span class="keyword">this</span>.readerValue());</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span>(<span class="keyword">this</span>.stringValue() != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> analyzer.tokenStream(<span class="keyword">this</span>.name(), <span class="keyword">this</span>.stringValue());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Field must have either TokenStream, String, Reader or Number value; got "</span> + <span class="keyword">this</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>但是即使这样，也不应该会报错，原来如果在create field字段中调用<strong>tokenstream</strong>方法，那么针对多值字段，那么同一个<strong>tokenstream</strong>对象就有可能可能共享，那么当Solr处理完第一个值结束的时候会将tokenstream进行重制，那么原有的reader就会失效，那么当Solr开始处理第二个值的时候由于共享的同一个tokenstream,那么对用的reader已经失效，就会抛出错误。所以我们需要每次生成不同的tokenstream就可以解决问题<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (val.startsWith(<span class="string">"[|"</span>) &amp;&amp; val.contains(<span class="string">"|]"</span>)) &#123;</span><br><span class="line">            target = val.substring(<span class="number">2</span>,val.indexOf(<span class="string">"|]"</span>));</span><br><span class="line">            <span class="keyword">if</span> (DynamicPayloadAttribute.FIELD_MAPPINGS.containsKey(target)) &#123;</span><br><span class="line">                String parsedData = val.substring(val.indexOf(<span class="string">"|]"</span>)+<span class="number">2</span>);</span><br><span class="line">                TokenizerChain tokenizerChain = (TokenizerChain)field.getType().getIndexAnalyzer();</span><br><span class="line">                Tokenizer tk = tokenizerChain.getTokenizerFactory().create(TokenStream.DEFAULT_TOKEN_ATTRIBUTE_FACTORY);</span><br><span class="line">                TokenStream ts = tk;</span><br><span class="line">                <span class="keyword">for</span> (TokenFilterFactory filter : tokenizerChain.getTokenFilterFactories()) &#123;</span><br><span class="line">                    ts = filter.create(ts);</span><br><span class="line">                &#125;</span><br><span class="line">                Analyzer.TokenStreamComponents components = <span class="keyword">new</span> Analyzer.TokenStreamComponents(tk, ts);</span><br><span class="line">                Reader stringReader = tokenizerChain.initReader(field.getName(),<span class="keyword">new</span> StringReader(parsedData));</span><br><span class="line">                tk.setReader(stringReader);</span><br><span class="line">                TokenStream stream = components.getTokenStream();</span><br><span class="line">                stream.getAttribute(DynamicPayloadAttribute.class).setPayloadType(target);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Field(field.getName(), stream, field);</span><br></pre></td></tr></table></figure></p><h2 id="参考的项目或者文章"><a href="#参考的项目或者文章" class="headerlink" title="参考的项目或者文章"></a><font color="#2C3E50">参考的项目或者文章</font></h2><p><a href="https://lucidworks.com/post/solr-payloads/" target="_blank" rel="noopener">SolrPayload 功能 Example</a><br><a href="https://lucene.apache.org/solr/guide/7_4/filter-descriptions.html#numeric-payload-token-filter" target="_blank" rel="noopener">Solr Numeric Payload Token Filter</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;如何动态设置Solr-Payload&quot;&gt;&lt;a href=&quot;#如何动态设置Solr-Payload&quot; class=&quot;headerlink&quot; title=&quot;如何动态设置Solr Payload &quot;&gt;&lt;/a&gt;&lt;font color=&quot;#0077bb&quot;&gt;如何动态设置Solr Payload &lt;/font&gt;&lt;/h1&gt;&lt;h2 id=&quot;问题背景&quot;&gt;&lt;a href=&quot;#问题背景&quot; class=&quot;headerlink&quot; title=&quot;问题背景&quot;&gt;&lt;/a&gt;&lt;font color=&quot;#2C3E50&quot;&gt;问题背景&lt;/font&gt;&lt;/h2&gt;&lt;p&gt;Solr 从6.x开始提供了index payload的功能，（payload是指可以指定为分词之后的每个term指定一个二进制的信息，用于针对每个term作出一定的行为，例如可以用来存储指定的score用于排序，也可以用来存储指定的数据，用于检查term的一定的检查），简单的查阅官方文档之后（这里使用solr7.7.2作为样例）,得知我们可以动态的设定每个term的payload（参考&lt;a href=&quot;https://lucidworks.com/post/end-to-end-payload-example-in-solr/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SolrPayload&lt;/a&gt;），也可以根据指定的token type设置payload数值(参考&lt;a href=&quot;https://lucene.apache.org/solr/guide/7_4/filter-descriptions.html#numeric-payload-token-filter&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Numeric Payload Token Filter&lt;/a&gt;)，但是上述两种方式都无法根据输入的变化而动态的改变payload的值。&lt;br&gt;
    
    </summary>
    
    
      <category term="Solr" scheme="https://www.fengqinglei.top/tags/Solr/"/>
    
      <category term="Payload" scheme="https://www.fengqinglei.top/tags/Payload/"/>
    
      <category term="动态设置" scheme="https://www.fengqinglei.top/tags/%E5%8A%A8%E6%80%81%E8%AE%BE%E7%BD%AE/"/>
    
      <category term="Dynamic" scheme="https://www.fengqinglei.top/tags/Dynamic/"/>
    
      <category term="Lucene" scheme="https://www.fengqinglei.top/tags/Lucene/"/>
    
  </entry>
  
</feed>
